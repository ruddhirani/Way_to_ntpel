{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_1_0.wav", "duration": 46.0, "text": "hello everyone welcome to lecture one of cs7 fifteen which is the course on deep learning in today\u2019s lecture is going to be a bit non technical we are not going to cover any technical concepts or we only going to talk about a brief or partial history of deep learning so we hear the terms artificial neural networks artificial neurons quite often these days and i just wanted you take you through the journey of where does all these originate from and this history contains several spans across several fields not just computer science we will start with biology then talk about something in physics then eventually come to computer science and so on so with that let us start"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_1_1.wav", "duration": 28.0, "text": "so just some acknowledgments and disclaimers i have taken lot of this material from the first people which i have mentioned on the bullet and there might still be some errors because its dates as back as one thousand, eight hundred and seventy-one so maybe i have got some of the facts wrong so feel free to contact me if you think some of these portions need to be corrected and it would be good if you could provide me appropriate references for these corrections so let us start with the first chapter which is on biological neurons as i said its spans several fields will start with biology"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_1_2.wav", "duration": 31.0, "text": "and we will first talk about the brain and neurons within the brainso way back in one thousand, eight hundred and seventy-one one thousand, eight hundred and seventy-three around that time joseph von gerlach actually proposed that the nervous system our nervous system is a single continuous network as opposed to a network of many discrete cells so his idea was that this is one gigantic cell sitting in our nervous system and it is not a network of discrete cells and this theory was known as the reticular theory"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_1_3.wav", "duration": 40.0, "text": "and around the same time there was the some breakthrough or some progress in staining techniques where camillo golgi discovered that a chemical reaction that would allow you to examine the neurons or the nervous tissue so he was looking at this nervous tissue using some staining technique and by looking at what you see in this figure on the right hand side the yellow figure even he concluded that this is just once single cell and not a network of discrete cells so he was again a proponent of reticular theory so this is about camillo golgi"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_1_4.wav", "duration": 35.0, "text": "and then interestingly santiago cajal he used the same technique which golgi proposed and he studied the same tissue and he came up with the conclusion that this is not a single cell this is actually a collection of various discrete cells which together forms a network so it is a network of things as opposed to a single cell there so that is what his theory was and this was eventually came to be known as the neuron doctrine"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_1_5.wav", "duration": 77.0, "text": "although this was not a consolidated in the form of a doctrine by cajal that was done by this gentleman so he coined the term neuron so now today when you think about art here about artificial neural networks or artificial neurons the term neuron actually originated way back in one thousand, eight hundred and ninety-one and this gentleman was responsible for coining that and he was also responsible for consolidating the neuron doctrine so already as you saw on the previous slide cajal had proposed it but then over the years many people bought this idea and this guy was responsible for consolidating that into a neuron doctrine interestingly he is not only responsible for coining the term neuron he is also responsible for coining the term chromosome so two very important terms were coined by this one person so now here is a question so around one thousand, nine hundred and six when it was time to give the nobel prize in medicine what do you think which of these two proponents say there are two theories one is reticular theory which is a single cell and then there is this neuron doctrine which is a collection of cells or collection of neurons that a nervous system is a collection of neurons so what do you think which of these two guys who are proponents of these two different theories who would have got the actual nobel prize for medicine"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_1_6.wav", "duration": 31.0, "text": "so interestingly it was given to both of them so till one thousand, nine hundred and six in fact way later till one thousand, nine hundred and fifty also this debate was not completely set settled and then the committee said both of these are interesting pieces of work we yet do not know what really actual what the situation is actually but these conflicting ideas have a place together and so the nobel prize was actually given to both of them and this led to a history of a some kind of controversies between these two scientists and so on"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_1_7.wav", "duration": 89.181, "text": "and this debate surprisingly was settled way later in one thousand, nine hundred and fifty and not by progress in biology as such but by progress in a different field so this was with the advent of electron microscopy so now it was able to see this at a much better scale and by looking at this under a microscope it was found that actually there is a gap between these neurons and hence it is not a one single cell it is actually a collection or a network of cells with a clear gap between them or some connections between them which are now known as synapses so this was when the debate was settled so now why am i talking about biology why am i telling you about biological neuron and so on so this is what we need to understand so there has always been interested in understanding how the human brain works from a biological perspective at least and around this time the debate was more or less settled that we have this our brain is a collection of many neurons and they interact with each other to help us do a lot of complex processing that we do on a daily basis right from getting up in the morning and deciding what do we want to do today taking decisions performing computations and various complex things that our brain is capable of doing now the interest is in seeing if we understand how the brain works can we make an artificial model for that so can we come up with something which can simulate how our brain works and what is that model and how do we make a computer do that or how do we make a machine do that so that is why i started from biological neurons to take the inspiration from biology"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_10_0.wav", "duration": 39.0, "text": "so welcome to lecture two of cs seven thousand and fifteen which is the course on deep learning so we will talk about mcculloch pitts neuron thresholding logic perceptrons and a learning algorithm for perceptrons and talk about the convergence of this algorithm and then we will talk about multilayer network of perceptrons and finally the representation power of perceptrons so let us start module one which is on biological neurons so remember during the history we had started all the way back in the 1880s when we spoke about biological neurons so we will just start there spend a few minutes on it and then go on to the computational models which is mcculloch pitts neuron"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_10_1.wav", "duration": 40.0, "text": "so now this is a course on deep learning so we are going to talk about deep neural networks now the most fundamental unit of a deep neural network is something known as an artificial neuron and the question is why is it called a neuron where does the inspiration come from so we already know that the inspiration comes from biology and more specifically it comes from the brain because we saw that way back in the 1890s this term neuron was coined for neural processing units or the cells in our brain so now before we move on to the computational neurons or the artificial neurons we will just see the biological neurons in a bit more detail and then we will move on from there"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_10_2.wav", "duration": 62.0, "text": "so this is what a typical biological neuron looks like so here actually there are two neurons this portion is called the dendrite so it is used to receive inputs from all the other neurons so that is the place where the input comes in then remember we said that in 1950s we discovered that these neurons are actually discrete cells and there is something which connects them so that connection is called a synapse and it decides the strength of the connection between these two neurons so there is an input there is some strength to the connection then once this neuron receives inputs from various other neurons it starts processing it so that is the central processing unit which is called the soma and once it is done this processing it will it is ready to send its output to other set of neurons so that output is carried on by the axon so we have inputs we have some weights attached to the input we have some processing and then an output so that is what a typical biological neuron looks like"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_10_3.wav", "duration": 26.0, "text": "and let us see a very cartoonish illustration of how this works right how the neuron works so our sense organs interact with the outside world and then they pass on this information to the neuron and then the neuron decides whether i need to take some action in this case the action could be whether i it should laugh or not right whether the input is really funny enough to evoke laughter so if that happens this is known as something that the neuron has fired"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_10_4.wav", "duration": 47.0, "text": "now of course in reality it is not just a single neuron which does all this there is a massively parallel interconnected network of neurons so you see a massive network here now the neurons in the lower level site so these neurons they actually interact with the sensory organs they do some processing based on the inputs so they decide whether i should fire or not and if they fire they transmit this information to the next set of neurons and this process continues till the information is relayed all the way back and then finally you decide whether you need to take any action or not again in which this case it should be laughter so that is how it works and when i say massively parallel interconnected network i really mean it because there are ten raise to eleven which is roughly one hundred billion neurons in the brain"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_10_5.wav", "duration": 23.0, "text": "now this massively parallel network also ensures that there is some division of work now what do you mean by that is not that every neuron is responsible for taking care of whether i should laugh or not or not every neuron is responsible for processing visual data some neurons may possess visual data some neurons may possess speeds data and so on so there is this division of work every neuron has a certain role to play so for example in this cartoonish example that we took"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_10_6.wav", "duration": 35.0, "text": "so there might be this one neuron which fires if the visuals are funny right whatever you are seeing is funny there will be one neuron which finds sheldons speech to be funny the way he speaks so that might be funny and there might be another neuron which actually finds the dialogue content to be funny and now all of this pass on the information to the next level and this guy would fire if at least two of these three inputs are funny so that means i have some threshold based on which i decide whether to react or not if it is really funny then only i laugh it otherwise i will not laugh"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_10_7.wav", "duration": 58.0, "text": "so the neurons in the brain as was obvious in the previous slide are arranged in a hierarchy and i will take a more realistic example where we look at the visual cortex so is this is the portion of the brain which is responsible for processing visual information right so as you see here you have our retina from where the information starts flowing and it goes through various levels so you see you follow the arrows and you will see there are several levels there is one level here then another here another here and so on right so it is again as i was trying to illustrate in that cartoon the information is relayed through multiple layers and then it goes all the way back to the spinal cord which decides that in this case i need to move the muscle right so that is what is being decided here right so the information flows through a hierarchy of layers and in this particular case i am going to focus on these three circled layers which are v1 v2 and ait right so these actually form a hierarchy and let us see what this hierarchy does right so at layer one you detect edges and corners so i am looking at you all i just see some dots and some shapes so that is what layer one recognizes i just recognize some edges and some dots and so on"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_10_8.wav", "duration": 50.0, "text": "now layer two tries to group all of these together and come up with some meaningful feature groups right so it realizes oh these two edges actually form the nose these two dots actually form the eyes and these two edges actually form the mouth right so that is slightly higher level of processing that it is doing and then layer three further collects all this and leads to higher level objects right so now it is realizing all these things put together is actually a human face right so you add edges and circles or dots then you had some feature groups and then the feature groups combine into objects right so that is how this hierarchy processes"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_10_9.wav", "duration": 31.105, "text": "so here is a disclaimer i understand very little about how the human brain works right and what you saw is a very oversimplified explanation of how the brain works right what i told you is there is an input a layer of networks which does a network which has many layers which does some processing and then you have an output right that is the very simplistic view that i gave you this is an oversimplified version but this version suffices for everything that we need for this course right this is not a biology or a neural processing course right so it is enough for this course so that is where we will end module one"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_100_0.wav", "duration": 7.0, "text": "let us start with module two which is about mcculloch pitts neuron"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_100_1.wav", "duration": 124.0, "text": "so as we are done this during the history lecture way back in one thousand, nine hundred and forty-three mcculloch and pitts they proposed highly simplified computational model of the brain so now let us see what\u2019s the motivation we know that our brain is capable of very complex processing it\u2019s capable of taking a lot of inputs from various sources and then help us taking various decisions and actions now what if you want a computer to do this we want a module which is very similar to how the brain works or at least how we think the brain works which takes a lot of inputs and then does some processing and helps us take a decision so what they proposed is this model which will take a lot of inputs and these inputs are all binary all these inputs that you see here these inputs are fed to this mcculloch pitts neuron which is an artificial neuron and it is divided into two parts so the first part collects all the input so remember you had these dendrites which were taking all the information from everywhere so this just collects all the information and then the second part is aggregation i have collected a lot of information from all the sources now the second function will decide what this aggregation is and based on that it will take a decision whether to fire or not so the output is again boolean if it\u2019s zero then neuron does not fire if it\u2019s one the neuron fires so let us take a concrete example so suppose i am trying to make a decision whether i should watch a movie or not so x1 could be is the genre of the movie thriller similarly there could be another variable say xn which says is the actor matt damon so these are all various such factors that i could take is the director christopher nolan the music given by someone and so on so all these are probably factors which help me decide whether i want to watch this movie or not and you want this neuron to help us make that decision"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_100_2.wav", "duration": 151.0, "text": "so now what is happening here is these all inputs they can be either excitatory or inhibitory so let me tell you what inhibitory is first so you are taking input from a lot of sources now see one of these sources or one of these inputs is am i ill today am i down with fever so if that input is on irrespective of who the actor director or whatever is i am not going to watch the movie right because i just cannot leave from my bed so these are known as inhibitory inputs irrespective of what else is on in your input features if this input is on your output is always going to be zero that means the neuron is never going to fire so you could think of it as suppose my mood is not good today i do not feel like getting up or if i injured my leg or anything right if any of these conditions is on irrespective of what the other factors are i am not going to watch the movie so that is an inhibitory input and excitatory input are on the other hand is not something which will cause the neuron to fire on its own but it combine with all the other inputs that you have seen could cause the neuron to fire and how so this is how so these are all the inputs that your neuron is taking all i am going to do is i am going to take a sum of these i am going to take aggregation of all of these so what does this count actually give me the number of inputs which are on the number of inputs which are value one that is all this aggregate this is a sum of all the ones in my input now this is what g does this is a very simple function is taking a sum of my inputs now the function y takes this as the input that means it takes this sum as the input and if the sum is greater than a certain threshold then it fires if the sum is less than the certain threshold then it does not fire so again see what is happening here is it is same as now if you depend on the actor director and genre and so on and you fine at least two of these three conditions are satisfied at least i am happy with the actor and the director even though the genre is not something that i care about i will watch the movie or you might be a very niche go movie watcher who only goes to a movie if the actor matches your requirement the director matches your requirement and the genre and the music and everything matches your requirement so you are threshold in that case it should be high so this is how it is going to help you make decisions now again a very simplified model and this is theta is called the thresholding parameter that is the value which decides whether the neuron is going to fire or not and this over all thing is known as the thresholding logic so this is what a mcculloch pitts neuron looks like"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_100_3.wav", "duration": 51.0, "text": "now let us implement some boolean functions using this mp neuron so from now on i will just called it mp neuron and we will try to implement some boolean functions using it so now why are we interested in boolean functions it is because we have overly simplified the way we take decisions we are saying that the way we take decisions is we take a lot of boolean inputs is actor matt damon and genre thriller and so on and based on that we produce a boolean output so an input is all booleans so we have x1 to xn which are all booleans and your output is also boolean so that is a boolean function that you are trying to learn from x to y is that clear you have x just happens to contain n different variables here ok and lot of decision problems you could cast in this framework you can just imagine right whether to come for lecture today or not again is you could cast in it depending on various boolean inputs"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_100_4.wav", "duration": 114.0, "text": "this is a very concise representation of the mcculloch pitts neuron what it says is it takes a few boolean inputs and it has certain threshold if the sum of these inputs crosses this threshold then the neuron will fire otherwise it will not fire that is the simple representation of the m p neuron now suppose i am trying to learn the and function when would the and function fire all the inputs are on so what should be the value of the threshold in this case three everyone agrees what about the or function one let us see a few more this function so let me tell you what this function is so you see this circle here so that means that this input is an inhibitory input if that is on then the neuron is not going to fire that is how i am representing it so now tell me what should the threshold for this be it is not so hard see if x2 is on it is not going to fire so you have four rows zero zero zero one one zero one one so two of those are ruled out and it is not going to fire now out of the remaining two when do you wanted to fire so what should be the threshold one now what about this function zero or three three is not even a valid option zero everyone agrees to that and what about this zero so you get this so now if you have a certain number of input variables and the function that you are trying to model the decision that you are trying to make is a boolean function then you could represent using these mp neurons whether all boolean functions can be represented in this way or not that is still not clear i am just showed you some good examples we will come to the bad examples later on here is the question"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_100_5.wav", "duration": 12.0, "text": "so can any boolean function be represented using a mcculloch pitts neuron so before answering this question we will see a bit of a geometric interpretation of what mp neuron is actually trying to do"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_100_6.wav", "duration": 47.0, "text": "so let us take or function where you have two inputs x1 and x2 and this neuron is going to fire if x1 plus x2 is greater than equal to one that is clear that is how the definition is now if you look at this x1 plus x2 greater than equal to one now let us ignore the greater than part first so we will just talk about x1 plus x2 equal to one what is this equation of a line everyone gets that ok now in this case since we are dealing with boolean inputs and we have two access x1 and x2 how many input points can we have four right zero zero zero one one zero one one"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_100_7.wav", "duration": 99.0, "text": "so you could have these four points so just note that this is an x1 and x2 axis but only four inputs are valid here this is not a real numbered access this is only boolean inputs possible here now what is the line x1 plus x2 equal to one tell you which line is that so one which passes through one zero here and zero one here this is that line now what do we want that for all those inputs for which the output is actually one they should lie on the line or on the positive side on the line and all those inputs for which the output is zero they should lie on the other side of the line is that happening so what is actually mp in unit actually learning linear decision boundary it just what it is doing in effect is actually it is dividing the input points into two halves such that all the points lying on that line right are sorry all the points for which the input should be zero lie below this line and all the points for which the output should be one sorry in both cases it should have been output so let me just repeat it all the points for which the output is zero lie below this line and all the points for which the output is one either lie on this line or above the line is that fine and so let us convince ourselves about this even it is not already clear from the equation for how many of you it is already cleared from the equation that this is exactly what it does for a large number of periods but still we will just do a few examples and move ahead"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_100_8.wav", "duration": 63.464, "text": "now for the and function what is the decision boundary it is x1 plus x2 no that is the decision boundary equal to two so again i have these four points only these four points are possible now where is my decision line passing through that one one and intercepting this somewhere around two zero and this around zero two so that is the line which i am interested in now again do you see that our condition is satisfied that all the inputs for which we want the output to be one are on or above the line and all the inputs for which we want the output to be zero or below the line now what about this function what is the threshold zero so what would the line be x1 plus x2 equal to zero which passes through the origin right and again all the points are either on or above the line so this part we are going to call as a positive half space and this we are going to call as the negative half space"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_101_0.wav", "duration": 8.0, "text": "now let us go to the next module which is perceptron"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_101_1.wav", "duration": 137.0, "text": "so far the story has been about boolean input but are all problems that we deal with we are only dealing with do we always only deal with boolean inputs so yeah so what we spoke about is boolean functions now consider this example this worked fine for a movie example where we had these as actor so much and his director and so on but now consider the example where you are trying to decide you are in oil mining company and you are trying to decide whether you should mine or drill at a particular station or not now this could depend on various factors like what is the pressure on the surface on the ocean surface at that point what is the salinity of the water at that point what is the aquatic marina aquatic life at that point and so on so these are not really boolean function the salinity is a real number density would be a real number pressure would be a real number and so on right and this is a very valid decision problem companies would be interested in doing this so in such cases our inputs are going to be real but so far mcculloch pitts neuron only deals with boolean inputs so we still need to take care of that limitation now how did we decide the threshold in all these cases i just asked you you computed it and you told me right but that is not going to work out i mean it does not scale to larger problems where you have many more dimensions and the inputs are not boolean and so on so we need a way of learning this threshold now again returning to the movie example maybe for me the actor is the only thing that matters and all the other inputs are not so important then what do i need actually i need some way of weighing these inputs i should be able to say that this input is more important than the others now i am treating all of them equal i am just taking a simple sum if that sum causes a threshold i am fine otherwise i am not fine but maybe i want to raise the weight for some of these inputs or lower the weight for some of these inputs so whether it is raining outside or not maybe does not matter i have a car i could go or i could wear a jacket or an umbrella or something so that input is probably not so important and what about functions which are not linearly separable we have just been dealing with the goody stuff which is all linearly separable but we will see that even in the restricted boolean case there could be some functions which are not linearly separable and if that is the case how do we deal with it so these are some questions that we need to answer"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_101_2.wav", "duration": 91.0, "text": "so first we will start with perceptron which tries to fix some of these things and then we will move forward from there so as we had discussed in the history lecture that this was proposed in one thousand, nine hundred and fifty-eight by frank rosenblatt and this is what the perceptron looks like do you see any difference with the mcculloch pitts neuron weights you have a weight associated with each of the input otherwise everything seems so this is a more general computational model than the mcculloch pitts neuron the other interesting thing is that of course we have introduced these weights and you also have a mechanism for learning these weights so remember in the earlier case our only parameter was theta which we are kind of hand setting right but now with the perceptron we will have a learning algorithm which will not just help us learn theta but also these weights for the inputs how do i know that actor is what matters or director is what matters given a lot of past viewing experience past given a lot of data about the movies which i have watched in the past how do i know which are the weights to assign this so we will see an algorithm which will help us do that and the inputs are no longer limited to be boolean values they can be real values also so that is the classical perceptron but what i am talking about here and the rest of the lecture is the refined version which was proposed by minsky and papert which is known as the perceptron model so when i say perceptron i am referring to this model so this diagram also corresponds to that"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_101_3.wav", "duration": 102.067, "text": "so now let us see what the perceptron does this is how it operates it will give an output of one if the weighted sum of the inputs is greater than a threshold so remember that in the mp neuron we did not have these weights but now we have these weighted sum of the inputs and the output is going to be zero if this weighted sum is less than threshold not very different from the mp neuron now i am just going to do some trickery and try to get it to a better notation or a better form so is this i have just taken the theta on this side now is this notice this here the indices were one to n now i have made it zero to n and the theta is suddenly disappeared so what has happened student w zero is minus theta right and x0 is one does anyone not get this right if i just start it from one to n then it would be summation i equal to one to n wi xi plus w0 x0 but i am just saying w0 is equal to minus theta and x0 is equal to one which exactly gives me back this right so very simple x0 equal to one and w0 is equal to minus theta so in effect what i am assuming is that instead of having this threshold as a separate quantity i just think that that is one of my inputs which is always on and the weight of that input is minus theta so now the job of all these other inputs and their weights is to make sure that their sum is greater than this input which we have does not make sense so this is how this is the more accepted convention for writing the perceptron equation so it fires when this summation is greater than equal to zero otherwise it does not fire"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_102_0.wav", "duration": 16.0, "text": "before we go to the next section which is on learning i just want to introduce the concept of errors and error surfaces and tell you what it relates to these multiple solutions that we were talking about"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_102_1.wav", "duration": 97.0, "text": "so for simplicity what we will do is we will just set the threshold to minus or minus w to one which is setting the threshold to minus one and now i will try different values of w1 and w2 ok so i was saying that there are multiple values of w1 and w2 possible and these are all real numbers we are not constrained by having them as boolean values so now this is one solution which i tried i tried setting w1 to minus one and w2 to minus one what is wrong with this line does it lead to any errors how many just one error so this makes an error of one out of the four inputs now let me just try some other values of w1 and w2 this line again one error what about this line not four three because zero zero is anyways on this side of a line so now given this now tell me that i my quest is to find these w so i would want to find w1 w2 and so on given this discussion on errors can you tell me a condition that i am looking for i want to find w1 w2 or up to wn such that errors are minimized and in the best case errors are zero so that is what i want so this just i want to make a case that these search for w\u2019s is driven by certain objective and this objective is to minimize the error so now since we are doing this let us plot the error surface corresponding to different values of w naught w1 and w2"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_102_2.wav", "duration": 249.111, "text": "once again for simpler analysis we will just keep w naught to be fixed at minus one and now what i have so just do not read this bullet as of now even this one so i have this w2 here so that is my one axis and i have w1 here which is my another axis now what i am going to do is i am going to try different values of w1 and w2 so this axis can go from minus infinity to plus infinity of course for showing the sake of showing here i have just had it from minus four to four so now what i am going to do is i am searching for some values of w\u2019s w1 and w2 so that my errors is zero and let us do a brute force and i will just try every value between minus four to four ok in fact one of the solutions which i proposed actually was this eleven eleven right that is the line which we saw on the previous slide and which led to zero errors and that is the dark blue surface here so how did i compute this error actually i just substituted minus sorry eleven eleven here and then i put in all the four values combinations for x1 x two and i realized that i am able to satisfy all of them so i do not get any error now instead of that if i had put something different so let me just go back to the previous slide which was see minus one minus one which is i think yeah somewhere around here right minus one minus one i guess so for that i am in this light blue region where the error was one i make errors for one of the inputs so it is a very brute force way of finding this and this is not going to work because we have lots of inputs to check but this is just to give you an intuition that we are looking at errors and we are trying to find a value of w1 w2 which minimize this error so that is the idea behind errors and error surfaces"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_103_0.wav", "duration": 7.0, "text": "we will now go to the next module which is the perceptron learning algorithm"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_103_1.wav", "duration": 8.0, "text": "we now see a more principled approach of learning these weights and threshold but before that we will just again revisit our movie example and make it slightly more complicated"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_103_2.wav", "duration": 66.0, "text": "now here what the situation is that we are given a list of m movies and a class associated with each movie indicating whether we like the movie or not so now we have given some data of the past m movies that we have seen and whether we like this movie or not and now instead of these three variables we have these n different variables based on which we are making decisions and notice that some of these variables are real they are not boolean anymore the rating could be any real number between zero to one ok and now based on this data what do we want is the perceptron to do actually so i have given you some data these factors i have also given you the label one and zero so if the perceptron if i tell you my perceptron has now learnt properly what would you expected it to do perfect match so whenever i feed it one of these movies it should give me the same label as was there in my data and again there are some movies for which i have a label one which are positive and some movies which i have a label zero so i am once again looking to separate the positives from the negatives so it should adjust the weights in such a way that i should be able to separate so that is the learning problem that we are interested in"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_103_3.wav", "duration": 144.0, "text": "so now with that i will give you the algorithm this is the perceptron learning algorithm we have certain positive inputs which had the label one we have certain negative inputs which had the label zero and now i don\u2019t know what the weights are and i have no prior knowledge of what the weights are going to be i need to learn them from the data so what i am going to do is i am just going to initialize these weights randomly as i am also going to pick up some random values for this so this should be small n so this should be small n and now here is the algorithm while not convergence do something so before i tell you what to do can you tell me what is meant by convergence when will you say that it has converged when it is not making any more errors on the training data right or its predictions are not changing on the training data so that is the definition of convergence now here is the algorithm i pick up a random from point from my data which could either be positive or negative so it comes from the union of positive negative basically all the data that i have i pick up a random point from there if the point is positive right and this is the condition which happens what does this tell me if the point was positive what did i actually want greater than zero but the condition is less than zero that means i have made an error so i have made an error then i will just add x to w i see a lot of thoughtful nodding and i hope you are understanding what is happening let us see so what is w actually a dimensional n dimension n plus one right because w naught is also inside there so actually there should be w naught also here right and what is x again n dimensional right and that is why this addition is valid so let us understand that w and x both are n dimensional now let us look at the other if condition can you guess what the other if condition is if x belongs to n and summation is greater than equal to zero then so that means you have completely understood how this algorithm works well that is so now consider two vectors w and x so remember what we are trying to prove is or get an intuition not prove actually get an intuition for why this works ok"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_103_4.wav", "duration": 79.0, "text": "so we will consider two vectors w and x and this is what my vectors look like very similar to the case that we are considering w0 to wn and one to n so this again x naught is just one now this condition that i have been talking about is nothing but the dot product how many of you have gone through the prerequisites for todays lecture ok good so it is just a dot product now we can just read write the perceptron rule as this instead of the dot product i mean instead of using that summation thing we can just say that it is a dot product now we are interested in finding the line w transpose x equal to zero so that is our decision boundary which divides the input into two halves now every point on this line satisfies the equation w transpose x equal to zero what does that mean actually so just a simple example is that if i have the line x1 plus x2 equal to zero then all the points which lie on the line satisfy this equation so you could have one minus one two minus two and so on but two two is cannot be a point on this line at every point lying on this line satisfies this equation so every point lying on this line actually satisfies the equation w transpose x equal to zero"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_103_5.wav", "duration": 44.0, "text": "so can you tell me what is the angle between w and any point on this line how many say how many of you say perpendicular why dot product is zero so if the dot product is zero they are orthogonal so that means if i take this line then my vector w is orthogonal to this it is orthogonal to this point or this point to this point to every point on the line which is just the same as saying that the vector is perpendicular to the line itself right as simple as that so the angle is ninety degrees because the dot product gives you the cos alpha and that is zero right and since it is perpendicular as i said to every point of the line it is just perpendicular to the line itself"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_103_6.wav", "duration": 94.0, "text": "so this is what the geometric interpretation looks like this is our decision boundary w transpose x and the vector w is actually orthogonal to this line and that is exactly the intuition that we have built so far now let us consider some points which are supposed to lie in the positive half space of this line that means these are the points for which the output is actually one now can you tell me what is the angle between any of these points and w or you guys are actually trying to tell me the angle we have got some measuring stuff no so i will give you three options i e equal to ninety greater than ninety and less than ninety less than ninety it is obvious from the figure now if i take any point which lies in the negative half space what is the angle going to be between them it is greater than ninety again obvious and it also follows from the fact that cos alpha is w transpose x by something and we know that for the positive points w transpose x is greater than equal to zero that means cos alpha would be greater than equal to zero that means the angle alpha would be less than ninety degrees and for the negative points w transpose x is actually less than zero that means cos alpha would be less than zero that means alpha would be greater than ninety degrees so it actually follows from the formula itself but it is also clear from the figure so keeping this picture in mind let us revisit the algorithm so this is the algorithm"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_103_7.wav", "duration": 71.366, "text": "now let us look at the first condition which was this now if x belongs to p and w transpose x is less than zero then means that the angle between x and the current w is actually greater than ninety degrees but what do we want it to be less than ninety degrees and our solution to do this is but we still do not know why this works now anyone knows why this works so let us see why this works so what is the new cos alpha going to be it is going to be proportional to this it is going to be proportional to this i will just substitute what w new is fine that means if cos alpha new is going to be greater than cos alpha what is alpha new going to be it will be less than and that is exactly what we wanted this angle was actually greater than ninety degrees so you want to slowly move it such that it becomes less than ninety degrees it is not going to get solved in one iteration and that is why till convergence so we will keep doing this i will keep picking xs again and again till it reaches convergence that means till we are satisfied with that condition"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_104_0.wav", "duration": 11.0, "text": "in this module we will talk about the proof of convergence for the perceptron or the learning algorithm that we saw in the previous module"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_104_1.wav", "duration": 10.0, "text": "so we have some faith and intuition that it actually works we just need to formally prove it that it actually converges so that is what we are going to do in this module"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_104_2.wav", "duration": 151.0, "text": "so before that a very few very simple definitions so if you have two sets of points p and n in an n dimensional space and we call say that these points are absolutely linearly separable if there exists some n plus one real numbers which has w0 to wn such that every point which belongs to p right p is the case where the output is one then these set of weights satisfy this condition and every point which lies in the negative set the set of weights satisfy this condition so nothing very different from what has we have been saying so far it is just formally defining it now our proposition is that if the set p and n are finite and there is a fixed number of points in that which was the case in the toy example that we were doing and which will be the case in most examples that we do and linearly separable the perceptron learning algorithm updates the weight vector ok before i go there ok let me not give you the definition and let me ask you the definition so now i have given this definition the first definition and given this part of the proposition can you tell me what do i need to prove if i need to prove that the algorithm converges that is one way of looking at it but what was happening in that wrong argument which was i was making that it continuously kept toggling that means i am not making a finite number of updates right i have to keep changing again and again and this process continues in a loop so that is how i am going to define convergence that the perceptron learning algorithm updates a weight vector of finite number of times it only needs to update it finite number of times and it will reach a configuration such that now it is able to separate the p from the n ok that is what the proof of convergence means so in other words if you are going to pick up these vectors randomly from the set p and n cyclically as we were doing in the toy example then a weight vector wt is found after a finite number of steps which will separate these two steps these two sets so that is what we are trying to prove so that is the definition of converge does it make sense"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_104_3.wav", "duration": 343.0, "text": "so proof is on the next slide and it is going to take me around five to ten minutes to prove it so just stay focused all right so here is a few set up right so i am going to before i go to the actual proof i am going to make a set up so that it becomes easier for us to prove it so the first thing that i am going to say is that if there is a point which belongs in negative set then the negative of that point belongs in the positive set and that is very clear because if the point belongs in the negative set then w transpose x is less than zero but then w transpose minus x would be greater than equal to zero right so i take the negative of the point i can just put it in the positive set so instead of considering these two different things p and n i am just going to consider one p prime which is an union of p and all the n points negative ok will the set up clear if this is a setup then what is the condition that i need to ensure for every point in p dash student refer time three hundred and fifty-seven w transpose p should be greater than equal to zero right so i do not care about the negative case i have just made everything positive now and it is i am not done anything wrong here it is just a simple trick ok and now this is how the algorithm will look in this setup these are the inputs with label one inputs with label zero n minus contains a negation of all the points in n and p prime is a union of these now again i start by initializing w randomly while convergence i will do something i will pick a random p from p prime now what is the if condition less than zero do i need the other if condition no right because everything is now positive ok and the other small thing that i am going to do is i am going to normalize p ok so that again does not mean because we are talking in terms of angles and i am not changing the direction of the vector i am just shrinking it right so i am just or maybe scaling it also i am just making it unit norm so that does not change anything so it is still everything still holds and in particular you can see here so if this condition was true this condition will also be true ok so so far just i am done some simple tricks to make things easier for me later on so now p has been normalized now remember that this data is linearly separable that is what we started the proposition if p and n are linearly separable then the perceptron learning algorithm will converge so now if p and n are linearly separable irrespective of whether we have the perceptron learning algorithm or not what do we know there exists a w star which is the solution vector right there exists at least one w star which is the solution vector right such that it will separate the p points from the n points so this vector which we do not know but we just know that it exists so you can refer to it so we will call this w star fine now we start the proof"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_104_4.wav", "duration": 62.407, "text": "now are you ok with this this is the minimum quantity right so any pi that i put in here it is always going to be greater than or worst case equal to delta now again this w2 itself i could write it as wt minus one plus pj because that also would have come up from some update in the previous step ok again this is there which i could call it as delta and still retain the greater than equal to here ok fine so let us see where are we heading with this now notice that we do not make a correction at every time step when i was running that toy algorithm i was not making a correction at every time step we were only making a correction at those time steps for which the condition was violated so now if i am at t\u2019th time step maybe i have made only k which is less than or equal to t corrections at max i would have made t corrections but it could have been less than that also so now every time we make a correction we are adding a value delta to this so at the time step t what would happen i had started off from w naught i have reached time safety and i have made a case that i have not made t updates i have made k less than equal to t updates so how many deltas would get added k delta so i could say that with respect to w naught where i had started from this is what this quantity is ok is that fine anyone has a problem with this"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_105_0.wav", "duration": 10.0, "text": "so in this module we look at linearly separable boolean functions again and we will try to make some more statements about them"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_105_1.wav", "duration": 16.0, "text": "so what do we have do so the guiding question that we have is what do we do about functions which are not linearly separable and let us see one such very simple function can you guess what function i am going to talk about all of you are paying attention in the first lecture"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_105_2.wav", "duration": 81.0, "text": "so here is the xor function now these are the set of inequalities that result from xor function i hope right now let us see the first condition implies that w naught should be less than zero second condition implies this third condition implies this fourth condition implies this just looking at this can you tell me can you find a configuration for w naught w1 w2 such that these inequalities can be satisfied together no right because two and three want it to be greater than minus one minus w naught and when you take an addition of that it has to be less than minus one so that is not going to happen so you see a contradiction so this is a simple boolean function which the perceptron cannot handle because it is not linearly separable it is not linearly separable there does not exist a line if there does not exist a line you cannot find the line in fact you can look at it visually so these are the red points for which the output should be zero or one and the blue points are the points for which the output should be zero if we need to change this i think we were using blue as positive and red as negative and you cannot just draw a line there is no way you can draw a line such that the blue points lie on one side and the red points lie on the other side so it is a simple two input function so it is not that i have taken a very contrived example"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_105_3.wav", "duration": 79.0, "text": "most real world data is not linearly separable and it always contains some outliers right so here maybe you have some data where you are trying to say that people which live in this part of the world belong to a certain or maybe people who live or work here have a certain qualification people who work in this company may have a certain different qualification and there might be some outliers right it is not that is always going be very clean so now what do i mean and it is not necessary that the points will only be outliers in fact there could be a clear case where there are no outliers but still you cannot find a line such that you separate the positive from the negative can you think of such an example good right this is clear data there is no outliers here as well i mean it is just saying that everyone who lies within this boundary has a certain characteristic and outside that boundary people have a different characteristic right and there is no outlier here but you cannot separate this data with a line so all functions that you deal with will not go or are not going to be linearly separable so we have to work around those right and while a single perceptron cannot deal with this we will show that a network of perceptron\u2019s can indeed deal with such data so that is where we are headed"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_105_4.wav", "duration": 10.0, "text": "so before going there we will discuss some more boolean functions in more detail and i will try to see what kind of nonlinearly separable boolean functions are there"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_105_5.wav", "duration": 626.504, "text": "so first of all how many boolean functions can you design from two inputs how many can you design sixteen looks like a good number from three inputs two hundred and fifty-six how many if you understand this let us see so let us begin with some easy ones that you already know right so these are two inputs x1 x2 what is this function always off the other extreme is always on and i have already given you the answer f sixteen so then you have the and function and or function then some other functions right so why did you reach sixteen actually because with two inputs we will have these four values to take care of and each of these are again binary so you actually have two raise to two raise to n right so for three inputs two raise to two raise to three would be two hundred and fifty-six now that is the easy part of these how many are linearly separable i will have to do any actually stare it in and seriously try to find the answer when you cannot really do that so turns out all of them except xor and in not of xor ok so for the two input cases there are two functions which are not linearly separable for n inputs how many functions would be not linearly separable it is an arbitrary n is not the answer you are not going to disappoint me not n ok but what is the answer so for n inputs we will have two raise two n functions of these we do not know how many are going to be not linearly separable that is not a solved problem although i encourage you to go and find the answer i am looking for a good will hunting kind of a moment but all it suffices to know is that there exists some which are not linearly separable and that everyone agrees that there exists some right and as n grows probably that number will increase and so on but it is not known exactly you cannot write it as a function so what we have done so far is looked at boolean functions how many boolean functions can exist and of that we just have concluded that there would be some which are not linearly separable"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_106_0.wav", "duration": 15.0, "text": "we will go to the next module where we talk about a network of perceptrons and then we talk about the representation power of a network of perceptrons so this module should have been titled as network of perceptrons so now in particular what we are going to see is how any boolean function whether linearly separable or not can be represented using a network of perceptrons"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_106_1.wav", "duration": 32.0, "text": "now what do i mean by represented during a network of perceptrons what it means is that i will give you a network of perceptrons you take any boolean function feed any value of x1 to xn and the network will give you the same y as it is expected from the truth table ok that is what representation means just to put it out clearly"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_106_2.wav", "duration": 106.0, "text": "and now i am going to again do a setup i am not giving you the solution i am just making some set up and then we will discuss the solution so for this discussion we will assume that true equal to plus one and false equal to minus one so instead of zero and one we will assume minus one and plus one and these are your inputs x1 and x2 we are taking the two input case and i will have four perceptrons first i will have four perceptrons and i will also have very specific weights connected to form the inputs to these perceptrons so red means minus one and blue means plus one right so the first two inputs are connected with a weight of minus one the next two inputs with minus one plus one plus one minus one and the last would be plus one now once i have this i will set the bias of all these perceptrons to minus two so that will that means they will fire only if they are weighted sum of the inputs is greater than two now after this i will have one more perceptron so i had two inputs i converted that to four values these four values are now going to feed into one more perceptron and these weights i will not fix them these are the weights that i am going to learn ok these and the final output of this perceptron which is the green perceptron is the output of the network right so now coming back to what i said that it can represent any function what i mean is that you take any function feed in any combination of x1 x2 this network will give you y and i am telling you that it will match the truth table of that function"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_106_3.wav", "duration": 51.0, "text": "now let us define some terminology this will also stay with us for the rest of the course so this network contains three layers the layer containing the inputs it is called the input layer very creative the middle layer containing the four perceptrons is called the hidden layer and the output layer which gives you the output is called the output layer output perceptron which gives you the output is called the output layer right so you have a input layer a hidden layer and an output layer and the outputs of the four perceptrons i am going to call them as h1 h2 h3 and h4 and the red and blue edges are called the weights for the layer one which we have not learned we have actually set them by hand and the weights for w1 w2 w3 w4 are called the weights for the second layer other the layer two weights and these are the weights that we want to learn"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_106_4.wav", "duration": 85.0, "text": "now i make this claim that this network it can take any boolean function it can implement any boolean function so this same network can implement any boolean function that means if i take this network and if i try to learn the values of w1 w2 w3 w4 for any boolean function whether it was originally linearly separable or not i will be able to implement it so isn\u2019t this an astonishing claim any boolean function do you think this is an astonishing claim well not really if you really understand what is happening here right so let us see what exactly is happening here so when will perceptron one fire when the input is false false zero zero will it fire for any other input when will perceptron two fire any other input same for the next perceptron same for the next perceptron so you start getting an intuition of what is happening here you do ok let us see so now for this particular network now that i have given you some intuition of what is happening basically every node or every neuron in the hidden layer is catering to one of the inputs and it will fire only for that input it will not fire for anyone else"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_106_5.wav", "duration": 161.0, "text": "so now let us try to implement the xor function and see what are the so now let us try to implement the xor function and see what are the set of inequalities that result from this earlier when we try to look at the set of inequalities we ended up with a contradiction let us see if that happens now so this is x1 x2 this is your xor function so that is just like any truth table then i am noting down the intermediate values and then my final input to the green perceptron is going to be summation of these and it will fire if this summation is greater than equal to zero or else it will not fire now for the first case when the input is zero comma zero what is h1 going to be one and everything else is going to be zero that is exactly what we saw in the previous slide so what is the summation going to be just w1 right so it is w1 h1 plus w2 h2 so on but h2 to h4 are zero so only thing that remains is w1 for the second case w2 for the third case w3 for the 4th case w4 so is it clear now what is happening let us go a bit more into detail right so now for the xor condition what are the conditions that we need w1 should be less than w0 because this should not fire w2 should be greater than equal to zero w3 should be greater than equal to sorry w naught not w is not zero and w4 should not fire so w4 should be less than w0 are there any contradictions here by design no right so we have made sure that for the final layer only one of these guys feeds to it so it does not matter what the remaining outputs are they do not interfere with each other unlike earlier where we had conditions like w1 should be something w2 should be something and then w1 plus w2 should be something there are no such contradictions here because we have made sure that every neuron in the middle layer actually caters to one specific input and now the weights in the final layer can be adjusted so that we get the desired output for that input so i can set whatever value of w1 i need to set so that i can fire the neuron in fact i could just fix w0 as zero and then i can adjust the weights of w1 w2 w3 w4 and i can implement the xor function so are you convinced that this can be used to implement any boolean function how many if you are not convinced so the negative question never works how many if you are convinced sure now what if we had three inputs"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_106_6.wav", "duration": 16.0, "text": "before that it should be clear that the same network can be used for any of the remaining fifteen functions and for each of these functions we will end up with a different value of w1 w2 w3 w4 but you will be able to satisfy the truth table right and you can go home and try it which i am sure you will do"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_106_7.wav", "duration": 15.0, "text": "ah so what if we have a function of three inputs two hundred and fifty-six what is two hundred and fifty-six no eight fine sure"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_106_8.wav", "duration": 36.0, "text": "so this is what it will look like and anything specific about the weights of the initial layer can you tell me what the weights would be just tell me red red red red blue blue whatever colours you like this thing first perceptron what would the weight colours be red red red then enough so this is how it will look right right and now this same thing will work with the same logic for any boolean function of three inputs you will get these eight inequalities and they will not interfere with each other and you can set the values of w1 to w8 so that you can satisfy it ok fine"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_106_9.wav", "duration": 8.0, "text": "so what if we have n inputs two power n perceptrons in the middle layer right ok"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_106_10.wav", "duration": 66.0, "text": "so now here is the theorem any boolean function of n inputs can be represented exactly by a network of perceptrons containing one hidden layer with two raised to n perceptrons and one output layer containing one perceptron we just saw an informal proof of this we just constructed i just gave you the answer it this is how you will get it now note that a network of two raised to n plus one perceptron is it sufficient or necessary or both sufficient yes that is what it says is it necessary no we already saw the and function which we can just represent using a single perceptron right so it is not necessary but it is sufficient so this is a very powerful theorem if you think of it right so now this whole objection right remember this history and when we have the c i winter when people showed that perceptron cannot handle the xor function that is for a single perceptron if you have a network of perceptrons you can actually have any boolean function but what is the catch as the value of n increases the number of neurons increases exponentially right but still in theory you could have a solution"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_106_11.wav", "duration": 33.0, "text": "now again why do we care about boolean functions i keep coming back to this why do we care about boolean functions because you took this and so the question that i the question that i want to answer is how does this relate back to our original problem right we know any boolean function can be implemented how do we go back to our original problem which is whether we like a movie or not right and you could see that there is a whole family of problems there right whether we like a movie or not whether we like a product or not whether i want to go home today or not yes no any kind of a yes no problem it is a whole family of problems there"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_106_12.wav", "duration": 29.568, "text": "so let us see so we are given this data from our past experience right so we are told that this is what the movie looks like these are the actor\u2019s director\u2019s joiners everything we also know whether we like these or not so we have a set of positive points and we have a set of negative points right and now we want to have a computational model which can satisfy this data that means once the model is trained once whatever algorithm i algorithm i use has converged it should be able to give me the correct output for a given input that is what we are interested in and that is a real classification problem that we are interested in now for each movie we are given these factors as well as the decision and i said pi\u2019s and ni\u2019s are positive and negative points the data may or may not be linearly separable it is not necessary that the data is linearly separable those were the goody cases it but in general that may not happen but do we worry about it now no what the previous theorem told us is that irrespective of whether your data is linearly separable or not i can give you a network which will be able to solve this problem modulo that it might be very expensive in the number of neurons in the middle layer but if you keep that aside i have a solution for this and that is why we care about boolean functions because many problems we could actually cast to it in a simplistic way if we ignore the real inputs and if you even think of the real inputs suppose it could take all values between zero to one you can always make it binary you could say that is the value between zero and one is the value between one and two and you could make it as small the scale as small as possible right so that is why we care about this"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_107_0.wav", "duration": 21.0, "text": "we are in lecture three of cs7015 and today we are going to cover the following modules we are going to talk about sigmoid neurons gradient descent feedforward neural networks representation power of feedforward neural networks"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_107_1.wav", "duration": 31.0, "text": "so let us start so here are some acknowledgments so for one of the modules i have borrowed ideas from the videos of ryan harris on \u201cvisualize back propagation\u201c they are available on youtube you can have a look if you want for module thirty-five i have borrowed ideas from this excellent book which is available online it is the url as mentioned in the footnote and i am sure i would have been influenced in borrowed ideas from other places and i apologize if i am not acknowledge them probably properly if you think there are some other sources from which i have taken ideas and let me know i will put them in the acknowledgments"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_107_2.wav", "duration": 8.0, "text": "so with that we will start with module thirty-one which is on sigmoid neurons so the story i had is that it is enough about boolean functions"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_107_3.wav", "duration": 145.0, "text": "now we have done a lot of boolean functions but now we want to move on to arbitrary functions of the form y is equal to f of x where x could belong to rn and y could belong to r so what do i mean by this so let me just explain this with the help of an example so i will again go back to our oil mining example oil drilling example where we are given a particular location say in the ocean and we are interested in finding how much oil could i drill from this place and that is what i would base my decision alright whether i want to actually invest in this location or not and then what we are saying is that this could depend on several factors so we could have x1 x2 x3 up to xn right where this could be the salinity of the water at that location so this could be a real number this could be the density of the water it is average density this could be the pressure on the surface of the ocean bed and so on and so forth so each of these values independently belongs to the set of real numbers so each of this is a real number and we have n of these so together they belong to rn so i can read that i have n such real numbers and i could just put them in a vector and say that i have a input x which belongs to r raised to n so we have this x which we can say belongs to rn and in this particular case we want to predict y we want to take this as an input and predictor y and what is y in this case you want to predict the quantity of oil that we could mine so what does ry belong to again a set of real numbers and it could be some gallons or litres or kill of water so this again belongs to r so these are the kind of functions that we are interested in now we want a function which takes us from i am having this x which belongs to rn right it is a vector of dimension n and takes us to a value belonging to r so you clearly see that this is different from the case when we had n variables each of this was just boolean so these were only zero one inputs now we have real inputs and these are the kind of functions that we are interested in"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_107_4.wav", "duration": 202.53, "text": "now can we have a network which can represent such functions now what do i mean by represent such functions we already spoke about this when we were doing boolean functions so what do we mean by representing the function we mean that if i am given a lot of training data right so i am given these x1 x2 each of these belongs to rn and i am also given the corresponding labels now i want a network which should be able to give me the same predictions as is are there in my training data so it should be able to take any of these x\u2019s as input and it should give me the same y i corresponding to it and i am saying approximately which means i am with some error rate whether if it is within some to with as long as it is close to the actual value i am fine with it so that is what i mean by a network which can represent such functions is that working definition of representing clear right so that is a very similar to the definition that we were used for boolean functions we had said that we should be exactly be able to get the truth table the network should be able to represent the truth table exactly so that is very similar to the definition that i am using here"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_107_6.wav", "duration": 8.0, "text": "so let us start so recall that a perceptron will fire if the weighted sum of it is inputs is greater than the threshold just recall that fine"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_107_7.wav", "duration": 74.0, "text": "so now i claim that the thresholding logic which is used by a perceptron is actually very harsh now what do i mean by that let us see so let us return to a problem of deciding whether we like or dislike a movie that is the same problem that we have been dealing with and now consider that we base our decisions only on one input which is the critics rating which lies between zero to one and this is what my model looks like it takes the input as the critics rating i have learned some weight for it and my threshold is five what does this mean it means that if for a given movie the rating is fifty-one will it predict like or dislike like so then i should go and watch the movie what about a movie for which the critics rating is forty-nine dislike so now you see what i mean by harsh so both these values are very close to each other but for one i say i like it for the other i say that i would not like it so it is not how we make decisions right you would have probably said something equal for both the movies you would have not given such a drastic decision"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_107_8.wav", "duration": 5.53, "text": "so why is this happening so you might say oh this is a characteristic of a problem that you have picked up maybe that is the critics rating which is between zero to one or something but i want to convince you that this is not a characteristic of the problem that i have picked up but this is something to do with the perceptron function itself so this is what the perceptron function looks like so this sum of all the inputs the weighted sum of all the inputs i am calling it by a quantity z and this is what i am going to plot on the this axis so this is my z axis now what does the perceptron say that when this value of z becomes greater than w naught or minus of w naught it will fire and when it is less than minus of w naught it will not fire that is what it says so this is a characteristic of the perceptron function itself it is going to have this"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_108_0.wav", "duration": 11.0, "text": "we will start module two which brings us to a typical supervised machine learning setup this is a very important module please pay attention"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_108_1.wav", "duration": 173.0, "text": "so now we have a sigmoid neuron we have taken care of the fact that the perceptron was a very harsh function so we have a smooth function so things are fine now what next where do we go from here what is my next topic going to be yes a lot of you are giving the right answers we need to learn these weights it does not help just to define the function this function depends on certain weights and now i need to give you an algorithm which will help you to learn these weights now remember when i talked about perceptrons before giving you an algorithm what did i revisit what did i talk about the error surfaces and then i had motivated from there that our goal is to find a set of weights which give us close to give us zero error in that case or in general\u2019s speaking generally they should give us a minimum error they should help us to minimize the error rate so i need to set up that similar story here so we will again revisit the concept of error"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_108_2.wav", "duration": 274.0, "text": "so this brings us to a typical machine learning setup which has the following components so this perhaps is the most important slide in the course and i will say this at least for one hundred other slides in the course but at least for now this is the most important so you are given some data xi yi and you are given n such elements right so let me just elaborate on this and give me i will give you some instances of this let me give you some instances of this right so one thing we say i already told you was this so this is my x and this is my y so one example which i gave was about movies so this was genre actor and critics rating and so on this is one instantiation of this problem i could also give you another instantiation which was i just told you oil right so this is how much oil can i get and here my factors were salinity density and so on there were many other factors so this was my x again x belongs to rn where n is some number integer and another example could be say fraud detection so i have a customer i am a bank i have a customer who has bought some credit card and i want to predict whether he or she would commit a fraud and i would look at factors like what is his occupation maybe salary maybe family size and so on there could be various factors which i could look at so here again this becomes an x ok and you could think of various such examples right where you are given an x and you are given a y ok so this is the data that you have now what is machine learning where does machine learning fit into this so we know that there is some relation which exists between y and x in each of these cases all of us are convinced that there is some relation so whether a person would commit a fraud would depend on these factors it is reasonable to assume that it is not a very wild assumption whether you would find oil at a location would depend on some of these factors and it is related and similarly for the movie case so there exists some true relation between x and y such that if i plug this value of x into the relation it would give me the value of y there exist a true relation this true relation could be governed by various things right it could be governed by physical laws example in the oil mining case it could be even governed by biological laws again the marine life in that location and so on it could be governed by economic law\u2019s it could be covered by psychology right we do not know why a person cheats what is his function that he is using when he cheats and so on right so these could depend on various factors but we all agree that some function exists hence we get these values for this particular input for every input we get a certain value so there is some function which takes us from the input to the output we do not know what this function is we never know in practice it is a very very complex function is all that we know we do not know this exact function if you knew this exact function then there is no problem to solve we just use that function and you can predict how much oil and all of us can become billionaires so that is not the case we do not know what this function is so then what do we do in machine learn we make an assumption ok we make an assumption that there is some function which takes x to y and this function is governed by some parameters and this is our approximation of how the real world works and now under this assumption we want to predict the parameters of this model given the data now let us take a very simple case where we could assume that y is equal to wx plus b i am taking this in the scalar single dimensional case now how would you estimate the values of w and b oh come on if i give you two data points you can estimate the value or should i write it that would jog your memory right this is how we all learn right so m and c you can estimate if i give you two data points so that is the simplest case now we will make similar assumptions but more complex functions and just as we could estimate m and c from the data we would expect to estimate ws also from the data so that is what the machine learning setup is so let us see"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_108_3.wav", "duration": 89.407, "text": "so the model when we talk about a machine learning model it is our approximation of the relation between x and y and we are free to make any such approximation so i could say that this is what i think is the relation between y and x and which is governed by some parameters w do you know what is this function have you seen this before no not sigmoid which model is this logistic regression ok but i could also have made a different assumption i could have made this assumption what do i get linear regression ok please note that this error on the slide ok and i could make some other assumption i could assume that y is actually a quadratic function of x i am free to make any assumptions the only thing i need to ensure is there is some parameter involved what is wrong with making this assumption if this is valid is this also valid if not why there are no parameters so no not for any x we will get the we will it will depend still depend on the value of x if i plug in different values of x i will still get a different output there is nothing to learn what do i do with all the data that i have there is absolutely nothing i can use it to learn i have just said that y is equal to one over one plus e raised to minus x i can ignore all the data that you had given me whenever you give me a new x i will just plug it into this formula and tell you the answer and that is bound to be wrong because i have not adjusted this formula now once i put in the ws it gives me this degree of freedom where i can now adjust the formula i can learn the ws in such a way that my predicted y\u2019s are very close to the actual y\u2019s so that is why we need always need a parametric form of course there is nonparametric learning also but i am just saying in this supervised setup we are thinking of models whether you have parameters so you have the data you have the model the model always has some parameters"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_109_0.wav", "duration": 24.0, "text": "we will start talking about artificial intelligence and this is titled as from the spring to the winter of ai so i am going to talk about when was this boom in ai started or when is that people started thinking and talking about ai seriously and what eventually happened to the initial boom and so"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_109_1.wav", "duration": 87.0, "text": "so let us start with one thousand, nine hundred and forty-three whereas i saying that there was a lot of interest in understanding how does a human brain work and then come up with a computational or a mathematical model of that so mcculloch and pitts one of them was a neuroscientist and the other one was a logician no computer scientists or anything at that point of time and they came up with this extremely simplified model that just as a brain takes a input from lot of factors so now suppose you want to decide whether you want to go out for a movie or not so you would probably think about do you really have any exams coming up that could be our factor x1 you could think about is a weather good to go out is it raining would it be difficult to go out at this point would there be a lot of traffic is it a very popular movie and hence tickets may not be available and so on so being kind of presses all this information you might also look at things like the reviews of the movie or the imdb rating of the movie and so on and based on all these complex inputs it applies some function and then takes a decision yes or no that i want to probably go for a movie so this is an overly simplified model of how the brain works is and what this model says is that you take inputs from various sources and based on that you come up with the binary decision right so this is what they proposed in one thousand, nine hundred and forty-three so now we have come to an artificial neuron so this is not a biological neuron this is how you would implement it as a machine right so that was in one thousand, nine hundred and forty-three"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_109_2.wav", "duration": 95.0, "text": "then along and then this kind of led to a lot of boom in our interest in artificial intelligence and so on and i guess around one thousand, nine hundred and fifty-six in a conference the term artificial intelligence was a formally coined and within a one or two years from there frank rosenberg came up with this perceptron model of doing computations or what perceptron model of what an artificial neuron could be and we will talk about this in detail later on the course and not tell you what these things are as of now just think of the a new model was proposed and this is what he had to say about this model right so he said that the perceptron may eventually be able to learn make decisions and translate languages do you find anything odd about this statement yeah so learn and make decisions make sense but why translate languages why is so specific why such a specific interest in languages so that you have to connect back to history so this is also the period of the cold war and there was always always a lot of interest there was lot of research and translation was actually fuelled by the world war and evens that happened after that where these countries which were at loggerheads with each other they wanted to understand what the other country is doing but they did not speak each other\u2019s language that is why there was a lot of interest from espionage point of view or from spying and so on to be able to translate languages and hence that specific require and lot of this research would have been funded from agencies which are interested in these things right and the defence or war or something"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_109_3.wav", "duration": 109.0, "text": "so and this work was largely done for the navy and this is an this is an extract from the article written in new york times way back in one thousand, nine hundred and fifty-seven or fifty-eight where it was mentioned that the embryo often this perceptron is an embryo of an electronic computer that the navy expects will be able to walk talk see write reproduce itself and be conscious of it is existence so i am not quoting something from two thousand and seventeen or eighteen this is way back in one thousand, nine hundred and fifty-seven fifty-eight why i am that is why i like the history part of it so recently there is a lot of boom or a lot of hype around ai that ai will take over a lot of things will take our jobs it might eventually we might be colonized by ai agents and so on so i just want to emphasize that i do not know whether that will happen or not but this is not something new we have been talking about the promise of ai as far back since one thousand, nine hundred and fifty-seven one thousand, nine hundred and fifty-eight right this not something new that people are talking about now it is always been there and to what extent this promise will be fulfilled is yet to be seen and of course as compared to one hundred and ninety-five thousand, seven hundred and fifty-eight we have made a lot of progress in other fields which have enabled ai to be much more successful than it was earlier for example we have much better compute power now we have lots of data now and all thanks to the internet and other things that you can actually crawl tons and tons of data and then try to learn something from a data or try to make the machine learn something from it so we have made a lot of progress in other aspects where which ai is now at a position where it can really make a difference but just wanted to say that these are not things which i have not been said in the past it has always been the it has always been considered to be very promising and perhaps a bit hyped also so that is about one hundred and ninety-five thousand, seven hundred and fifty-eight"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_109_4.wav", "duration": 61.0, "text": "then now what we talk about what is all the for the past eight to ten years at least when we talk about ai talking about deep learning and that is what this course is about largely about deep learning i am not saying that other and what deep learning is largely about if i want to tell you in a very layman nutshell term is it is about a large number of artificial neurons connected to each other in layers and functioning towards achieving certain goal so this is like a schematic of what a deep neural network or a feed forward neural network would look like now this is again not something new which is up in the last eight to ten years although people have started discussing it a lot in the last eight to ten years look at it way back in one hundred and ninety-six thousand, five hundred and sixty-eight opposed something which looked very much like a modern deep neural network or a modern feed forward neural network and in many circles he is considered to be one of the founding fathers of modern deep learning"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_109_5.wav", "duration": 4.0, "text": "so that is about that"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_109_6.wav", "duration": 16.0, "text": "right from one thousand, nine hundred and forty-three to one thousand, nine hundred and sixty-eight it was mainly about the springtime for ai and what i mean by that that everyone was showing interest in that the government was funding a lot of research in ai and people really thought that ai could deliver a lot of things on a lot of fronts"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_109_7.wav", "duration": 52.0, "text": "for various applications health care defence and so on and then around one thousand, nine hundred and sixty-nine an interesting paper came out by these two gentlemen minsky and papert which essentially outlined some limitations of the perceptron model and we will talk about these limitations later on in the course in the second or third lecture but for now i will not get into a details of that but what it is said that it is possible that a perceptron cannot handle some very simple functions also so you are trying to make the perceptron learn some very complex functions because the way we decide how to watch a movie is a very complex function of the inputs that we considered but even a simple function like xor or is something which a perceptron cannot be used to model that is what this paper essentially showed and this led to severe criticism for ai and then people started losing interest in ai and lot of government funding actually subsided after one thousand, nine hundred and sixty-nine"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_109_8.wav", "duration": 24.0, "text": "all the way to one thousand, nine hundred and eighty-six actually this was the ai winter of connectionism so there was very little interest in connectionist ai so there are two types of ai one is symbolic ai and the other is connectionist ai so whatever we are going to study in this course about neural networks and all that probably falls in connectionist ai paradigm and there was no interest in this and people i mean hard to get funding and so on for these seventeen to eighteen years"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_109_9.wav", "duration": 30.0, "text": "and that was largely triggered by this study that was done by minsky and papert and interestingly they were also often misquoted and what they had actually said in that papers so they had said a single perceptron cannot do it they in fact said that a multi layer network of perceptrons can do it but no one focused on the second part that a multilayer network of perceptron people started pushing the idea that a perceptron cannot do it and hence we should not be investigating it and so on right so that is what happened for a long time and this known as the winter the first winter"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_109_10.wav", "duration": 86.0, "text": "then around one thousand, nine hundred and eighty-six actually came this algorithm which is known as back propagation again this is an algorithm which we are going to cover in a lot of detail in the course in the 4th or 5th lecture and this algorithm actually enables to train a deep neural network right so deep network of neurons is something that you can train using this algorithm now this algorithm was actually popularized by at rumelhart and others in one thousand, nine hundred and eighty-six but it is not completely discovered by them this was also around in various other fields so it was there in i think in systems analysis or something like that it was being used for other purposes in a different context and so on and rumelhart other and others in one thousand, nine hundred and eighty-six were the first to kind of popularize it in the context of deep neural networks and this was a very important discovery because even today all the neural network so most of them are trained using back propagation right and of course there have been several other advances but the core remains the same that you use back propagation to train a deep neural network right so something this was discovered almost thirty years back is still primarily used for training deep neural networks that is why this was a very important paper or breakthrough at that time"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_109_11.wav", "duration": 45.0, "text": "and around the same time so again interestingly so back propagation is used in conjunction with something known as gradient descent which was again discovered way back in one thousand, eight hundred and forty-seven by cauchy and he was interested in using this to compute the orbit of heavenly bodies that is something that people care about at that time today of course we use it for various other purposes one of them being discovering cats and videos or even for medical imaging or for describing whether certain have of cancer is being depicted in a xray or things like that there is a lot of other purposes for which deep neural networks enhance and hence back propagation gradient descent and other things are being used for it but again these are not very modern discoveries these are dated way back thirty years and even gradient descent is almost one hundred and fifty years and so on so that is what i wanted to emphasize"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_109_12.wav", "duration": 1205.586, "text": "and around the same time in one thousand, nine hundred and ninety or one thousand, nine hundred and eighty-nine there is this another interesting theorem which was proved which is known as the universal approximation theorem and this is again something that we will cover in the course in the third lecture or something like where we will talk about the power of a deep neural network so again the importance of this or why this theorem was important will become clear later and when we cover it in detail but for now it is important to understand that what this theorem said is that if you have a deep neural network you could basically model all types of functions continuous functions to any desired precision so what it means in very layman terms is that if the way you make decisions using a bunch of inputs is a very very complex function of the input then you can have a neural network which will be able to learn this function right in many laymen terms that is what it means and if i have to hype it up a bit or i have to say it in a very enthused and excited manner i would say that basically it says that deed neural networks can be used for solving all kinds of machine learning problems and that is roughly what it says but with a pinch of salt and a lot of caveats but that is what it means at least in the context of this course so this is all around one thousand, nine hundred and eighty-nine and despite this happening some important discoveries towards the late end of 80\u2019s which was back propagation universal approximation theorem people were still not being able to use deep neural networks for really solving large practical problems and a few challenges there was of course the compute power at that time was not at a level where it could support deep neural networks we do not have enough data for training deep neural networks and also in terms of techniques while back propagation is a sound technique it is to fail when you have really deep neural network so when people try it training a very deep neural network they found that the training does not really converge the system does not really learn anything and so on and there were certain issues with using back propagation off the shelf at that time because of which it was not very successful so again despite these slight boom around eighty-six to ninety where some important discoveries were made and even follow up in ninety-two ninety-three and so on there is still not a real big hype around deep neural networks or artificial neural networks and at time again a slump a slow winter right up till two thousand and six"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_11_0.wav", "duration": 16.0, "text": "in this module we will try to learn these parameters and initially we will try to learn them by guesswork and i will show that that is actually infeasible that is why we need a more principled approach"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_11_1.wav", "duration": 21.0, "text": "so we will keep the supervised machine learning setup in mind and now we will focus on this model and discuss an algorithm for learning the parameters which are w and b given some data using a giving appropriate function objective function so that is what we are going to focus on"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_11_2.wav", "duration": 78.0, "text": "now sigma here stands for the sigmoid function the logistic function in this case when this sigma is actually the logistic function and now i am going to simplify this further so that it helps us to do a better analysis i am just going to consider the case where i am just in one input and the bias ok and also following the normal terminology in the literature this w naught from now on i am going to call it b because that is the normal convention b stands for bias so i have two parameters w and b which i need to estimate ok and this is my model for the movie example and the other change which i am going to make is instead of deciding whether i like or dislike which is one zero the setup that i am going to work with is that i am giving the critics rating and i want to predict the imdb rating so i am given a real value and i also want to predict a real value for no particular reason this just makes life easier for me for explaining a few things but the same thing or the same algorithm would also hold if you add a binary output right and you will see that later on in the course so here is a setup clear we just have two parameters w and b and we are going to assume that y belongs to real numbers it is a imdb rating and x also belongs to real number it is a critics rating"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_11_3.wav", "duration": 32.0, "text": "now let us see what we are given as training is a set of points we are given some n training pairs and now we understand what this means that means for a lot of movie i am giving the critics rating and i am also given the true imdb rating for them of course in the two variable case this does not make much sense but just bear with me and now the training objective is such that whatever my function predicts which is a function of w x and b that should be very close to the true output that i know this is the function that i want to optimize now let me ask you this"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_11_4.wav", "duration": 92.0, "text": "i am trying to tell you that i am going to give you an algorithm for training this network suppose i have trained this with two data points five comma two and twenty-five comma nine right at the end of training i will give you some values of w and b let us call them w star and b star these are the final values of w which i have given w and b what do you expect from these values what do you expect at the end of training if i say now the network has learned what do you expect you are still going to the test case i am just talking about the training still we expect such that what happens if i plug in at the end of training if i plug in the value five here what should happen nine so this is what you expect at the end of training if you plug in the value five it should be very close to two the output and if you plug in the value twenty-five it should be very close to nine this is exactly what you expect and this is what training means ok fine in other words we hope to find a sigmoid function such that these two points lie on that function can you imagine a geometric picture for this what would happen actually how many if we can imagine it ok how many of you get it now this is what will happen right so you will get a sigmoid function such that these two points lie on that fair ok and that exactly means that when i plug in this value i will get this value and when i plug in this value i will get this value right so that is what it means"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_11_5.wav", "duration": 1.0, "text": "so let us see this in more detail"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_11_6.wav", "duration": 77.0, "text": "and now what we will do is our quest is for this w star and b star i will try to find this manually i will do some random guesswork and try to find this because i do not have any clear principle algorithm for finding it as of now so i will just use some guesswork so i will give my initial guesswork as w equal to five b equal to zero for no reason i just picked up some values right and this is what the function that i got what does this mean this function an error so the sigmoid formula should be here we should have this sigmoid formula here so is this a good are you happy with the solution if i give you are you happy with this solution is this good bad ugly has to be something bad we will not call it ugly ok so why is it bad it is not passing through those points i will ask you a question how bad is it can you assign a number to it we are always good at qualitative stuff but quantitatively can you tell me a number how bad is this can you tell me a way of finding how bad this is i already told you in detail how to find that how bad it is the loss function right"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_11_7.wav", "duration": 5.0, "text": "we have the loss function let us see that again and see if we can find out how bad this is"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_11_8.wav", "duration": 42.0, "text": "so this is what my loss function is ok and i have two data points i will just expand it out fine now i will plug in the values i know this is nine and i will compute the value of f twenty-five i will plug in this and i will plug in this ok and this is what i get so this is how bad it is what did we actually expect it to be in the good case zero so this is not zero this is seventy-three so now we have a quantitative handle on how bad this is ok so let us keep this in mind and let us try to continue guessing so we want the loss function to be asked close to zero as possible we are not there yet"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_11_9.wav", "duration": 88.0, "text": "so then i make a different guess i say let me try minus ten zero what happened now is it now good bad ugly now let us call it ugly right so it is worse and how do i know it is worse because i plugged it in to the loss function and i got a value which is greater than the value at which i was so i clearly know this is bad so now this is how my mind is working right oh i as far as w was positive things looked at least i was close to zero in the first decimal now when i made it negative that does not look good so let me just keep it positive and keep increasing it right so i saw ninety-four and i also tweaked the b of it i have done complete random guesswork right now what happened good bad ugly better ok now what will you do what would your next case would be make w even more positive perhaps that would help and be even more negative and so on i can continue in this manner and actually get close very close to the solution so i can do this guesswork and find these values but it is still an educated guess right i am not guessing in the dark this is what is helping me drive towards those guesses and i am just looking at these values and making an educated guess right and that is the educated guess which i took that probably making w even more positive would help but this is still brute force in a sense right this is not something that you would want to do when you have one hundred one thousand parameters and so on right and one million data points and so on"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_11_10.wav", "duration": 11.0, "text": "so let us look at something which is better than our guesswork algorithm ah so we are not there yet actually on the next slide i am still going to talk about the guesswork algorithm"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_11_11.wav", "duration": 151.0, "text": "and eventually we will get to something which is better than the guesswork that ok so since we have only two points and two parameters what i can do is i can take all possible values of w and b right that is what i was trying i was picking up some values of w and b why just pick some values of w and b i will pick all possible values of w comma b right and i will fix the range i cannot fix pick it from minus infinity to infinity but i will pick a range i will say from minus six to six let me try all values of w comma b compute the loss and plot it right let me tell something about this error function because this is going to stay with us for quite some time so what you see here is something like a flying carpet this is colour coded red is bad red are the places where the error is high blue is good blue are the places where the error is low darker the shade of blue lower the error darker the shade of red higher the error so in particular if i look at this point what has happened is i have taken the corresponding value of w comma b right which is say minus four comma minus one right something like that i have plugged that value into my loss function and i got this as the loss function this has the loss value and that is what i have plotted for all values between minus six to plus six and minus six to plus six for w and b so everyone understands how i have constructed this error surface now this of course becomes and now what i can do is once i see this error surface i know how good this is the point where i need to be this is the darkest ah shade and this is where the error is the lowest so i can just pick a w comma b value which lies there this is fine for this toy example where you just have two parameters but this becomes untractable once you have more data points and many more parameters and that is what happens in most real world applications right so this is not a feasible way of going about things right and here again note that i have only taken the range from minus six to six i do not even know what will happen if i have to look at all values of w comma b right maybe there was something outside here right which was even more lower error or something right so i do not really know that so i cannot really use this so i need something better than this plotting the error everywhere and finding it order that is pure brute force or surrogate to this was the guesswork algorithm but which is again something we cannot do for if you have large number of parameters so everyone gets this that this is a way of finding the solution but this is not feasible right that is the only point i am trying to make"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_11_12.wav", "duration": 9.0, "text": "and we look at the geometric interpretation of what was actually happening in the case of the guesswork algorithm with respect to the error surface"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_11_13.wav", "duration": 155.189, "text": "so i had chosen some values of w comma b the first value that i chose actually gave me an error of if you remember it was some seventy-three or something like that right so that is the point then i decided to take a very random guess and my error actually increased so you see that i am actually climbing up on this error surface i have gone from a slightly darker shade of blue to a lighter shade of blue right and then i corrected myself and then kept moving in a direction where i was going towards the darker and darker shades of blue so what i was actually doing is i was trying to traverse the error surface and land up in the good regions which were the dark blue regions now what i want to do is i want an algorithm which will allow me to do this in a principled manner which is neither brute force nor guesswork so that is what we learn in that module"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_110_0.wav", "duration": 12.0, "text": "in this module we will talk about gradient descent"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_110_1.wav", "duration": 8.0, "text": "so what we want to do is find a more efficient and principled way of navigating the error surface"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_110_2.wav", "duration": 5.0, "text": "and the goal is to find a better way of doing this"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_110_3.wav", "duration": 33.0, "text": "so let us start by setting up things we will define some notations and some parameters and so on and from there on we will try to come to the algorithm ok so my parameters in this case were w comma b what i am going to do is i am going to put them into an array or a vector right and call that vector as theta so theta is the vector of parameters and theta belongs to r r what r2 right there are two parameters here so it is a two dimensional vector"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_110_4.wav", "duration": 422.011, "text": "now what i want is again what i will do is i do not know what the value of w comma b is so i started with a random guess so that is always going to be my starting point i will always start with a random guess and from there on move on to good values now once i have started with a random guess i want you to tell me some changes that i can make to w and b so that i land up in better situations right that means i land up in situations where the error is less is that fine so that change in w and b i am going to call it as delta w and delta b and that again is a vector which is storing these two values so this is the picture right i want to take theta and i want to add a small change to it so this is my theta this vector is actually theta right this is the theta vector i want to add a small change to it which is again a vector this is delta w comma delta b such that i will get a new value for theta new so theta new would be what actually theta new is equal to w new comma b new is that fine that is what theta new means"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_111_0.wav", "duration": 3.0, "text": "before we move on to the next modulate some small corrections from yesterday\u2019s class"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_111_1.wav", "duration": 30.0, "text": "so one was this partial derivative it should have been dou w square so we already taken one derivative with respect to w and now you are taking another derivative it is the gradient of the gradient and similarly should this should have been dou b square and this should have been dou w dou b"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_111_2.wav", "duration": 194.0, "text": "the other small thing which i wanted to say was so when i was executing this algorithm right so i forgot to mention that just notice what is happening is the black dot that you see the black dots that you see right and which are very close to each other actually because you are just making small movements those are the changes in the w comma b values and the red dots are the corresponding loss to that w comma b values right just to clarify so that is why you see a movement on the w b plane which is this movement and as you keep changing that your loss function changes and it becomes better and better right that means it goes closer to zero"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_111_3.wav", "duration": 29.0, "text": "so this was one thousand, nine hundred and eighty-nine ok what is the significance of this why do we care about such arbitrary functions and what does this theorem telling us actually it is of course telling us something about the representation power of a multilayer network of sigmoid neurons but why is this important so we will see that"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_111_4.wav", "duration": 94.0, "text": "so this the remainder of the lecture i have borrowed ideas from this url you should actually read this it is a very interesting book it is available online for free very illustrative so please take a look at it ok"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_111_5.wav", "duration": 31.0, "text": "now we make an observation that such an arbitrary function can actually be approximated by a lot of something that we call as tower functions these are all single i mean pulse functions which you have many of these and you could have an approximation right and you can see that this approximation is bad at many places but still it is an approximation it largely gives you the same shape as the original curve what would happen if i increase the number of such tower functions"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_111_6.wav", "duration": 34.0, "text": "student refer time six hundred and twenty-nine the approximation would improve right if i keep increasing it the approximation would go more and more better right so now just try to keep things in mind whether i write in the theorem right you can make it arbitrarily close to the actual value that means you can keep doing something so that your approximation becomes better and better and you already see something of that sort this is still in the sense of a figure we need to relate this back to a neural network but you see that as i am increasing these tower functions i become approx arbitrarily close to the actual function"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_111_7.wav", "duration": 30.0, "text": "now this is what is actually happening right i have multiple such tower functions i am adding them up all of them are shifted in time so this tower function is actually this one this tower function is actually this one and so on right and i have not drawn the remaining ones i am taking all of these tower functions adding them up and getting my original function right and the more such tower functions have the better is the approximation"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_111_8.wav", "duration": 97.0, "text": "now you make a few observations right all these tower functions are actually the same what is the only difference they just shifted and their magnitude changes right but they are all tower function right so let us think of this that if i know how to make a rectangle then i can make any rectangle right i just need to change the size of the rectangle and maybe shift it or oriented differently or something right so they are all similar i just need to learn how to draw a tower right that is what my quest is now if i take the original input salinity pass it through multiple such blocks each block is capable of making a tower function and each of these would give me one of these towers that i am looking for and i am looking for so many of these right if i have as many such tower makers then i could get these towers i could just add them up and then get the original function back and the more these i have the better is my approximation right so i am taking as input the salinity and trying to predict the oil does this make sense still we have not figured out a neural network way of doing this we are still building intuitions of how to do this now our job now is to figure out what goes in this black box that is the tower maker and how does it connect to neural networks if you figure that out then our story is complete then we know that a neural network can actually do this and that precisely proves the statement which i had made that it can it can represent arbitrary functions so we will figure this out over the next few slides"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_111_9.wav", "duration": 173.0, "text": "now if you take the logistic function and set w to w to a very high value what will we get just try to think about it the answer is already written but i want you to imagine it w covers what student refer time nine hundred and thirty-one the slope right as i make w very high what will happen is i will get the so let us try changing the value of w ok i just increase the value of w and see what happens to the sigmoid curve"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_111_10.wav", "duration": 62.0, "text": "now can we come up with a neural network to represent this operation i want a sigmoid neuron i was working with a sigmoid neuron with some arbitrary weights right so that i recover that step function can you imagine now given x i want this tower function and that is exactly what one of the blocks was right so what i am asking you is oh god so i am asking you to give me a neural network for this can you think of it can you try imagining it two neurons in the hidden layer how many of you agree with that ok can you can you take some more time to imagine what it would be and i have already ok right"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_111_11.wav", "duration": 219.0, "text": "so this w one b one if i set it appropriately i will get this step function if this w two b two i set it appropriately i will get this step function now i needed to subtract one from the other right so i will do plus one minus one this is just a simple addition and i will get this is that fine everyone agrees with this this is just a adder right this is just an aggregator everyone gets this so now i have given you the tower maker if you put enough of these tower makers and learn the w\u2019s appropriately what will you get that function that we were needed so you can approximate it arbitrarily to any precision that you want as long as you keep increasing the number of these units right so these units actually give you one tower more of these units that if you have actually this much this is the input ring the more such tower makers that you have the more is the bars that you will get and then you can approximate everyone gets the intuition behind this fine ok this all is always good in one dimension"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_111_12.wav", "duration": 2.0, "text": "so now i want to show that even in 2dimensions i could come up with arbitrary i could come up with a neural network which could actually approximate this and again what will i look for a tower maker right i just want something which can make towers and approximate it"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_111_13.wav", "duration": 41.0, "text": "so this is what a 2dimensional sigmoid looks like slightly incorrect because i have what i have done is i have actually said w two to zero so if you actually i would want you to do this go back and plot this for w one equal to three and w two equal to three just go back and plot this and see what you get you will not get such a smooth such a nice looking s but you will still get something which looks like looks like a snakes hood right so in still get that s shaped function it just that it would be bent at some points and it be thinner at some points and broader at the other points so just go back and see and then you will realize what is happening right"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_111_14.wav", "duration": 103.0, "text": "so here again what we want to figure out is from the single sigmoid i was able to take you to a tower function right from a 2dimensional sigmoid what does a tower mean here and how do i take you to the tower so that is what i want to do so i have said w two equal to zero and i will it will become obvious why i have done that so just understand what the figure is doing right so this if you just look at this is like the cross cut right so you are looking at the front view of this figure and that is just the sigmoid function without the w two right and now since i have said w two equal to zero no matter what i set x two to the same function will get repeated throughout that axis do you get that so that is why this entire function is just getting repeated throughout this axis and then you just get a similar s shape function everyone gets that how many of you do not get that how many of you get that so this if you look at the front view this is the sigmoid of one variable but since i have said w two to zero no matter what i change x two to the function is going to remain the same so it will just get copied throughout the x two axis is that fine with you now what will happen if i increase w two sorry w one same thing right it will just keep shifting till it becomes almost like a 2d step function ok now what will happen if i increase b shift i can do the same thing here also same logic applies here also ok"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_111_15.wav", "duration": 46.0, "text": "now what is the next step that i am going to do take two of these which are shifted by some point and then subtract what will i get everyone had this figure in mind so just see right so this portion both are zero so zero minus zero would be zero this portion this is one but this is zero so that would be one minus zero and again in this portion both of them are one so one minus one would be zero so you will get this kind of function would you like to live in such a tower i am very serious yes or no no why it is open from two sides right you cannot live in this tower so you want something which is a closed tower right so how will you do that give me an intuition we will do the reverse thing what will be set to zero w one ok"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_111_16.wav", "duration": 26.0, "text": "and this is how it would look the orientation would change and again so notice that this is your sigmoid function and since i have set x one to zero no matter what i change along the x one axis the same function gets copied and you get a nice looking a sigmoid function now again i will do the same thing i will increase the w i will get a close to a step function i will increase the b i will move along this axis"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_111_17.wav", "duration": 208.811, "text": "next step take two of these subtract get what another tower function this is also not a tower that you like to stay in so what do i do now add them sure add this tower to the other tower"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_112_0.wav", "duration": 173.0, "text": "so welcome to lecture four of cs7015 the course on deep learning today we will talk about feed forward neural networks and back propagation so quick recap of the story so far it so we started with mp neurons we saw there were some problems with the mp neurons they could handle only boolean inputs and boolean outputs and threshold needed to be hard coded so from there we moved on to perceptrons which allowed for real inputs real outputs and sorry real inputs and binary outputs and we also learned an algorithm for learning these weights and parameters right so we need there was no need to hand code these parameters anymore but then we found that for a single perceptron there is a limitation it cannot it can only deal with functions which are linearly separable so then we went on to a multi layer network of perceptrons and we proved by illustration that it can handle any arbitrary boolean function whether linearly separable or not the catch is that you will need a large number of neurons in the hidden layer right then we also observed that perceptrons have this harsh thresholding logic so which makes the decisions very unnatural it is forty-nine it is negative fifty-one is positive so you wanted something more smooth so the smoothest approximation to this step function which is the perceptron function was a sigmoid function sigmoid is a family of functions and we saw one such function which was logistic function and then we saw that it is very smooth now it is continuous and differentiable now for the sigmoid neuron on a single sigmoid neuron we saw a learning algorithm which was gradient descent and we proved principally that it will always go in the direction where the loss decreases right so that is what is the basis for gradient descent and then we graduated from a single neuron to a network of neurons and made a case that such a network of neurons with enough neurons in the hidden layer can approximate any arbitrary function right ok so i have told you that it can approximate any arbitrary function what does that mean and what is the thing in the network that does all this all the tower functions and the tower functions depend on weights and biases so there in that illustrative proof again we were adjusting the weights and biases by hand right we knew that we wanted these very tiny tower functions and we were doing it now from there where should we go student refer time two hundred and thirty-nine we need an algorithm to learn these weights and biases right so that is what back propagation is so today i am going to formalize these feed forward neural networks we just did it by illustration the other day i will introduce you to the terminology and see what the input outputs are and so on and then we will look at an algorithm for learning the weights in this feed forward neural network"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_112_1.wav", "duration": 200.0, "text": "let us begin so this a lot of this material is inspired by the video lectures by hugo larochelle on back propagation he has a course on neural networks it is available on youtube you can check it ok so let us first begin by introducing feed forward neural network right"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_112_2.wav", "duration": 219.0, "text": "now what about the output layer n cross k and the biases k k dimensional ok so this is what the network looks like but now i have to give you some function so i have just i have shown you a diagram but what does it mean mathematically because remember that we are always interested in writing something of the form y is equal to function of x right and that is not well defined yet"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_112_3.wav", "duration": 402.0, "text": "it could be logistic tanh linear anything right so we will see some of these functions later on ok now the activation at layer i sorry they are supposed to be activation at the output layer the activation at the output layer is given by the final function which is f of x is equal to o of a of so let us see so this is a three in our case l was equal to three because we had l minus one hidden layers and the lth layer was the output layer right so this is a l so this is what i have computed here that light green part of the figure that you see right now based on that i want to produce an output so that is someone had asked me a question that why do we always choose sigmoid because sigmoid will clamp the output to zero to one what if i want to predict the amount of oil which will not be between zero to one right that is why for the output we will use a special function that will call the output function and later on i will show you that it depends on the task at hand so it is going to change with the task that we are going to do right so we are just going to say that the final output which is h of l is equal to some function of the pre activation at that layer is this terminology clear to everyone how is each function operating is that clear to everyone"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_112_4.wav", "duration": 280.388, "text": "and the algorithm that we are going to see today for learning these parameters is called gradient descent but we will use it with back propagation where back propagation will help us to compute gradients it is ok it does not it does not make sense at this point that is what the lecture is supposed to be about right so and what is an objective function student refer time one thousand, seven hundred and seven loss function so i could just go with this loss function right ok there is an error here i thought we corrected this there is a summation so actually these are vectors right so this does not make sense so you should have summation j equal to one to k yij minus yij does that make sense so this is the vector y hat ok for the i th example it will be called as y hat high i which will have k elements right so y hat i one y hat i two up to y hat i k right so that is what my predictions are and i will have the corresponding true vector also i am trying to take the difference between them which is going to be an element wise difference everyone understands the error in the slide how many of you do not get it how many of you get it if you do not get it please raise your hands it is a minor thing i can correct it and how does deep neural networks fit into these this paradigm"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_113_0.wav", "duration": 16.0, "text": "now we will move on to the next module where we want to learn the parameters of feed forward neural networks and we first start with some intuition and then mathematical details"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_113_1.wav", "duration": 7.0, "text": "so we have introduced feed forward neural networks and we are now interested in finding an algorithm which can allow us to learn the weights of this network"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_113_2.wav", "duration": 128.0, "text": "so recall our gradient descent algorithm this is how it looked ok i had initialized those two parameters w naught b naught and then i was iteratively doing this in a loop at every step i was moving in a direction opposite to the gradient at that step now can i write this a bit more compactly we can write using vectors"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_113_3.wav", "duration": 27.0, "text": "so we can still use the same algorithm except that del this grad of hat of so now i could just say that theta two hat i mean initialized all parameters and theta naught right compute the gradient with respect to all of them and then do this update right i could just instead of putting them in matrices i could just think of them as a large vector just had initially i had just had w comma b now this vector is even more large in fact i will show you actually how it is"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_113_4.wav", "duration": 111.0, "text": "so this is the grad with respect to theta looks very nasty now this is how nasty looks right so you have this weight matrix w one you have the derivatives with respect to first element of w one all the way up to the last element last element so with respect to all the n cross n elements of w one what is the next entry going to be w two hundred and eleven to student refer time three hundred and thirty-two w2nn next after wl11 ok and then after this ok student refer time three hundred and forty-one what is remaining biases right so you have b11 to b1n this slight error here but intentionally this actual is k because k is not equal to n right the last layer has only k parameters whereas so that it looks ok is this clear so is this are all the partial derivative that we need right you do not need to worry about taking a partial derivative with respect to our matrix it just boils down to taking the partial derivative with respect to all elements of the matrix so earlier you just had two parameters now you have these n cross n plus n cross n upto l right so l into n cross n plus l into n that many number of parameters is what you have you get the calculation right or rather you have l minus one layers each of which has n cross n parameters right and l minus one layers which also have the biases so these are the w\u2019s these are the b\u2019s then the output layer one layer which has n cross k parameters and k cross one bias so these are all the number of parameters that you have and this is exactly what this size of this matrix is right it has all these parameters and you need to compute the partial derivative with respect to each of these parameters"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_113_5.wav", "duration": 56.0, "text": "so this is what grad theta is composed of it is composed of the partial derivatives with respect to all the parameters of your network ok so now if someone gives you each of these quantities same oracle give you each of these quantities then can you apply gradient descent right you can use the exactly the same algorithm that you are using earlier just the sizes of earlier vectors changes how many of you are convinced that now you can use that gradient descent there is not a trick question how many of you convinced how many of you not convinced assuming that someone has given you these quantities right i know that it is hard to compute we will see how to compute that but let us assume someone has given you this then you can use gradient descent that is what the case i made in the previous slide right that you could initialize with all the parameters compute the gradients with respect to all the parameters and just do this update fine so now we need to answer two questions first is this is the key question"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_113_6.wav", "duration": 667.583, "text": "because we are taking derivative of what loss functions so we need to know what the loss functions that is the crucial question right and then we are taking derivatives with respect to all these elements so whatever i was told you that assume that oracle gives you now you have to do the hard work and actually find it out right so if you can answer these two questions then we are done we have an algorithm for learning the parameters of feed forward neural networks we all agree that if you have these two elements then we have done so here i will end this module"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_114_0.wav", "duration": 9.0, "text": "we go on to the next module where we will be talking about output functions and loss functions"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_114_1.wav", "duration": 987.0, "text": "the question that we are going to focus on is how to choose the loss function but i will show you that it is tightly coupled with the choice of the output function also remember that we had said that we have a special o function as the output function i have not told you what that o is and now that is what we are going to define"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_114_2.wav", "duration": 82.0, "text": "so now so this was for whatever we have done so far right till this point this was for regression right now i wanted to enter into classification for which i have built this set up of how to take the difference between two distributions so now let us consider this problem where we have this situation and which is a classification situation that you are given four possible classes out of which one is the correct class and this is the true data given to you this is the true distribution all the probability mass is focused on one of these classes now we want to given an image classify this into one of k classes if you could again use a squared error loss but since we are dealing with probability distributions here we want to use something special so before we get to what the special is going to be what do i first need to tell you in the earlier case my output was not bounded was it also dependent was there any condition on if the imdb rating is something the critics rating should be something else or the rotten tomatoes rating should be something else no now in this case is there a tightly coupled behavior between the outputs why because they should sum to one we are trying to predict a probability distribution so the sum should one right so i need an output function which ensures this you get this setup"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_114_3.wav", "duration": 136.0, "text": "now we should ensure that y hat is also a probability distribution whatever we are predicting is also a distribution so now can i use a sigmoid function yes it will give me values between zero to one and probabilities are between zero to one but the sum would not be y so sigmoid is ruled out"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_114_6.wav", "duration": 1573.871, "text": "so now let us look at the summary so if your outputs are real values what is your output activation going to be linear what is the loss function going to be squared error if your output is a distribution what is the output function going to be softmax what is this loss function squared error cross entropy right now this grid light actually takes care of a wide range of problems that you will see right think of any examples that have been giving you so far movie prediction or sentiment prediction or image classification or anything all of that you can fit into this frame of it and so if you know these two loss functions how to deal with them then you can deal with a large class of problems that you are going to deal and for the rest of this lecture which will happen tomorrow we are going to focus on this at this particular output function and this particular loss function how do we compute i have a loss function what i am going to compute now the gradient with respect to all the parameters so this is what we are going to focus on right so we have seen the loss function in detail we have seen that the loss function is tightly coupled with the output function now we are all set but given this loss function how do we start computing gradients of this loss function"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_115_0.wav", "duration": 70.0, "text": "this lecture is on backpropagation and feed forward neural networks so we introduced a feed forward neural networks we saw the input layer hidden layer and the output layers and we saw that the output layer actually the output function depends on the task at hand and we considered two main tasks one was classification the other was a regression for regression it made sense to use a linear layer at the output because we did not want the outputs to be bounded they could be any range and for the classification problem we realized that we want a special kind of output because we are looking for a probability distribution over the output and for that we use the softmax function and in both cases we used a different kind of a loss for the regression problem the squared error loss made sense because we predict some values and we want to see how far we are from those values but for the other case the classification we realize that it is a distribution so maybe we could use something which allows us to capture the difference between the true distribution and the predicted distribution"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_115_1.wav", "duration": 51.0, "text": "and therefore we had this figure emerging which was depending on the output whether it is real values or probabilities you will have different types of output activation functions and different types of losses and of these combinations today we are going to focus on softmax and cross entropy and our aim is to actually find these gradients remember there are many of those we have seen this large matrix which had many such partial derivatives and we want to find that entire matrix i hopefully do it in a way that it is not a repetitive we could compute a large number of partial derivatives at one go so before we look at the mathematical details we just get an intuition for backpropagation"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_115_2.wav", "duration": 26.292, "text": "and then we will get into the gory details of how to actually compute these gradients and partial derivatives so this is the portion that we are in we are intended to ask these two questions and this is where we are"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_116_1.wav", "duration": 28.0, "text": "so this is the output and when i say i want to compute the gradient with respect to output unit what do you actually mean what is the quantity that i am looking for i will help you out actually what i meant by output unit is this entire thing right so i actually meant al\u2019s ok but it is it is a fair answer and even y hat is a fair answer ok in fact am going to start with y hat and then go to al so i will have to start with this guy and then come to this guy"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_116_2.wav", "duration": 324.0, "text": "so this is the loss this is y hat which is equal to y one hat y two hat up to yk hat so these are the k values that we have here and we are looking at cross entropy that means we are looking at the classification problem right so we have got a distribution over the k classes that is what y hat looks like and we know that one of these guys is the right class maybe say y two so the loss function is minus log of y hat two because two is the correct class in this toy example that i am considering ok so the loss function i am just repeating the definition right that is how the loss function is"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_116_4.wav", "duration": 67.0, "text": "so what if i what do i have so far i have this quantity what does till which part of the diagram am i currently the dash green part dark green part i am till here i need to go till the light green party that is collectively the output unit ok although i have divided into two halves but when i say output unit i mean that output neuron right complete neuron so what i am actually interested in is these quantities or more specifically ok this is what i am interested in what is this one of those guys right this al is actually al1 up to alk right so this is one of those guys so this is going to be the gradient or this is going to be the derivative a partial derivative sorry ok now what do how do we proceed from here"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_116_5.wav", "duration": 87.0, "text": "now i will again have to compute this you already know that good but before that i want you to answer one question right so y hat l what is y hat l it is the output corresponding to the correct class does it depend on an arbitrary al i so in the previous thing we saw that only when i is equal to l there is a connection in this case is there a connection always or only when i is equal to l student refer time eight hundred and two always why softmax so student refer time eight hundred and four denominator has all the ali\u2019s right so this is there it is y hat l in the numerator of course it only has this unit which corresponds to the l th probably did not choose my variables very well so l th component of a capital l right and but in the denominator you have the entire sum which means that every output guy here each of these dark green guys depends on each of the dash green guys light green guys good so that is at least settled that we always the we can always compute this partial derivative we do not need an if else here there is nothing like l is equal to i then what will happen it will always have this partial derivative"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_116_6.wav", "duration": 92.0, "text": "so we will now derive the full expression for this so this is what we are interested in is this fine so this is a function of the form so you are taking how do i say this so this is log of a function so first you will take the derivative with respect to log and then push the partial derivative inside right so that would be minus one by y hat l and then the derivative with respect to y hat l now what is y hat l the softmax function right so it is the l\u2019th entry of the softmax function applied to that output vector what is the output vector al right so it is the l\u2019th entry of the softmax or l\u2019th entry of the function applied to the output vector so this was our al what is our output right so now one of these guys here is the l th guy and one of these guys here is the l\u2019th guy right so what you do is you take this you apply the softmax function to it which again gives you a vector and now you are interested in the l\u2019th component of that vector that is what this quantity means it should be clear now"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_116_7.wav", "duration": 65.538, "text": "now i will just do some simple math stuff here and we should be able to derive this is it fine am just replaced by the actual softmax formula this is a derivative of the form u by v right what is the formula for that yeah it perfectly right yeah so this is what it would be right i mean it is you all know this i am not going to spend time on this so now am just going to substitute the values here yeah it is getting a bit nasty but it is not very difficult right so so this so this is our g of x so am taking the derivative of that then this is this one over h of x you can just figure it out right anyway it everyone just read this for a few seconds and let me know if this is not clear this is g this is h in this formula right have just substituted the gs and hs in this now what is this quantity going to be it is derivative of the form e raise to x right so it is e raise to x always student refer time one thousand, one hundred and thirty-three if i is equal to l right so now we have this dependence because we are looking at a numerator but the numerator only depends on the l th entry right so now you are trying to take the derivative of the l th entry with respect to some arbitrary i th entry so only if l is equal to i you will get the derivative right"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_117_0.wav", "duration": 6.0, "text": "now we will go to the gradient with respect to the hidden units"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_117_1.wav", "duration": 17.0, "text": "so this portion so you already see there is a repetition here and i do not need to treat each hidden unit separately i can just have a formula for the hidden unit and then i could compute it for all the hidden units so that is what our aim is so let us do some simple stuff first and then you will come back to it"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_117_2.wav", "duration": 115.0, "text": "so suppose you have a variable x you compute two functions from that one is x square the other is x cube i will call this as y one and i will call this as y two and i take y one and y two and compute a z which is say a log of y one by y two now what i am interested in is this what is the answer for this how do you get this this is a fair question to ask y one y two are functions of x z is a function of y one y two hence z is a function of x so i can compute this derivative and i can ask for this derivative how would you compute it if i cannot really do this right so if this path did not exist then it is trivial it is just the chain rule along one path but now you have two paths so what will happen add them right so can you tell me a formula for that so let me know if this makes sense to you ok does this make sense now let me complicate this a bit just let me just do it as y three now student refer time two hundred and fifteen what will happen student refer time two hundred and sixteen that is all right so you see that if there are multiple paths you can just add up the chain rule across all these paths right that is what chain will across multiple paths does"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_117_3.wav", "duration": 597.0, "text": "so with this we will go back to this figure so now i am interested in i am interested in going to the hidden layers again i will do this to bit calculation where i first asked for this guy and then i will ask for the light blue guy right and am going to look at one unit at a time now what is the what am i interested in the derivative of the loss function with respect to say d h two two right the second unit of the second hidden layer"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_117_4.wav", "duration": 313.0, "text": "so this is what it will look like ok now consider these two vectors one is this vector what does this vector look like this is a collection of all the partial derivatives so this is just a collection of all the partial derivatives nothing new we have already seen this now what is this vector actually in fact i have started with the matrix and i am saying look at this vector what does this mean this i plus one is just the layer in which the matrix is right so that index we do not really care about for a matrix what we care about is the i comma j index ok now what does this dot comma j mean all the i\u2019s belonging to j that means the dash column j\u2019th column everyone gets this this is all the i\u2019s or all the entries belonging to the j\u2019th column so it is effectively just the j\u2019th column so it is one comma j two comma j up to k comma j right so these are two valid vectors now tell me what is this quantity going to be this is the dash between two vectors dot product dot product between two vectors is a student refer time one thousand, three hundred and forty-three is a summation over element wise thing ok i have said enough now try to connect this is a very simple maths the column that you will ever get in your life try to connect this to something which is already there in the slide how many of you think the answer is this this into this plus this into this plus this into this and just write it as a formula you will get this everyone sees that ok so now i have a compact way of writing one of these entries"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_117_5.wav", "duration": 92.0, "text": "so that is again very simple again what will i do i will compute it with respect to ok what is this this is the guy that i am interested in the generic i not the l\u2019th one right the generic i this is what the vector looks like the gradient vector looks like i want each of these guys ok now i will take one of those and i will write it as this ok what am i doing am saying that i already have the entries up to here ok at a very general level even here i could have said the same thing remember that i had said that the output layer you can always write as hl right so even at the output layer i could say this chain rule always holds how many of you agree with that i want to go from the loss function to one of the lighter blue guys so am saying that i can go through the intermediary dark blue guys that is all i am saying i have just compressed this entire path into up to the dark blue guy remember i had said earlier that i will be compressing this chains now how many of these quantities do you know the first one is what we computed on the previous refer time one thousand, eight hundred and fifty-two the second one looks very difficult sorry so h ij is nothing but sigmoid of a ij or any nonlinearity of the a ij so i can just write this derivative as i will just write it as sigma prime ok"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_117_6.wav", "duration": 50.668, "text": "or g prime is this fine now i have it with respect to one unit what will i do go to the gradient fit it all these values now simplify this what is this a vector right what is this another vector there is a one to one correspondence between them so you have two vectors and you are doing a one to one multiplication what is this student refer time one thousand, nine hundred and forty-three how many of you say dot product dot product is always a what is the output here student vector can it be a dot product can it be a dot product no please empathic no ok so what is it going to be an element wise multiplication and this is how you denote that ok so what is this called you had a multiproduct right so this is every element of one vector multiplied by the corresponding element of the other vector ok so now again the entire vector we can compute at one row right i am not i am when i am teaching this i am telling you how to compute one element and then go to the gradient but when you are going to implement this we are just going to compute the gradient at one go"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_12_1.wav", "duration": 108.0, "text": "before we move on to the next module a quick summary of what we have done so far so we introduced feed forward neural networks and we wanted to learn the parameters right from the last layer to the first layer and we figured out that what we can do is that we can just use the gradient descent algorithm as it is except that we have this small problem that we have so many parameters now and located at differ different points in the network right some at the initial layer some at the final year and you want to compute the derivatives or the partial derivatives with respect to all of these if you can do that put them all in this large matrix then we can just use gradient descent as it is so that is what we figured out and then we wanted to find out the gradients with respect to or the partial derivatives with respect to all these parameters so then we realize that this can be done using chain rule because there is a path from your output which is the loss function to any of these weights so we just need to follow that path and apply this smart this chain rule smartly and just sum up the derivatives across all the paths that lead to that weight so in that process we started from the output layer we just treated it a bit special because the output function is special and this is the last layer so we just first computed the gradient with respect to the output layers then we figured out how to compute the gradients with respect to any of the hidden layers and now if you are at a particular hidden layer now the weights that feed into this layer we could or we have not reached there so now the next thing that we need to do is that we have computed the gradients with respect to any of these hidden layers and now we want to find the gradients with respect to the parameters which is the weights and the biases so it is the do you all remember this or it is all long history or the story is back right fine so now we are at the last point which is computing gradients with respect to parameters"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_12_3.wav", "duration": 119.0, "text": "so let us do it right so you have ak1 ak2 ak3 that is your ak vector ok you have bk1 bk2 bk3 plus wk1 one yeah i know again this is one of those silly things but if everyone does not raise their hands and compelled to do this so h k minus one one hk minus one two hk minus one three ok so let us take one of these guys right so a k one can you tell me the formula for that student refer time seven hundred and thirty plus first row ok one two this one three now can you tell me this quantity so what is i here one ok so i want this by w k i j right so i is one so i can take any of the j so let me take j equal to two so what is it going to be this will go off this is constant this is constant only this term remains and the derivative is hk minus one two which is j right so that is what the formula says so i have a formula for one of these guys ok and that is a generic formula so always remember if you cannot figure out what it is just write it down in scalar terms just add up all the terms and you will get the formula right so now this is what the chain rule is going to be"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_12_4.wav", "duration": 142.087, "text": "so this is what it is going to be this is one element of that tensor this is how that entire thing is going to look i have just flattened it out and put it here"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_13_0.wav", "duration": 5.0, "text": "when this deep revival happened so in two thousand and six a very important study was or a very important contribution was made by hinton and salakhutdinov"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_13_1.wav", "duration": 86.0, "text": "sorry if i have not pronounced it properly and they found that a method for training very deep neural network effectively now again the details of these are not important we will be doing that in the course at some point but what is the important take away here is that while from one thousand, nine hundred and eighty-nine to two thousand and six we knew that there is an algorithm for training deep neural networks and they can potentially be used for solving a wide range of problems because that is what the universal approximation theorem said but the problem was that in practice we were not being able to use it for much it was not easy to train these networks but now with this technique there was revived interest and hope that now actually can train very deep neural networks for lot of practical problems this sparked off the interest again and then people started looking at all such of thing right that even this particular study which was done in two thousand and six will actually be very simple to something done way back in nine thousand, one hundred and ninety-three and which again showed that you can train a very deep neural network but again due to several factors may be at that time due to the computational requirements or the data requirements or whatever i am not too sure about that it did not become so popular then but by two thousand and six probably the stage was much better for these kind of networks or techniques to succeed so then it became popular in two thousand and six"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_13_2.wav", "duration": 77.0, "text": "then this two thousand and six to two thousand and nine people started gaining more and more insights into the effectiveness of this discovery made by hinton and others which is unsupervised pre training right that is what i spoke about on the previous slide unsupervised pre training and they started getting more and more insights into how you can make deep neural networks really work so they came up with various techniques some of which we are going to study in this course so this was about how do you initialise the network better what is the better optimization algorithm to use what is the better regularization algorithm to use and so on so there were many things which were started coming out at this period two thousand and six to two thousand and nine and by two thousand and nine everyone started taking note of this and again deep neural networks of artificial neural networks started becoming popular that is when people realised that all this all the negative things that were tied to it that you are not able to train it well and so on have slowly people have started finding solutions to get by those and maybe we should start again focusing on the potential of deep neural networks and see if they can be used for large scale practical application so this two thousand and six to two thousand and nine was again a slow boom period were people were again trying to do a lot of work to popularize deep neural networks and get rid of some of the problems which existed in training them"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_13_3.wav", "duration": 25.0, "text": "now from two thousand and nine onwards there was this series of success is which kind of caught everyone which made everyone to stand up and take notice right that this is really working for a lot of practical applications starting with handwriting recognition so around two thousand and nine these guys won handwriting recognition competition in arabic and they did way better than the competitor systems using a deep neural network and then this was a success"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_13_4.wav", "duration": 22.0, "text": "so this was an handwriting recognition and then there was speech so this shown that various existing systems the error rate of these system could be seriously be significantly reduced by using deep neural networks or plugging in a deep neural network component to existing systems right so this was handwriting and then speech"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_13_5.wav", "duration": 35.563, "text": "then again some kind of pattern recognition which was on handwritten digit recognition for mnist this is a very popular data set which had been around since ninety-eight and a new record was set on this data so this is the highest accuracy that was achieved on this data set around that time in two thousand and ten sorry and this is also the time when gpus entered the same so before that all of the stuff was being done on cpus but then people realised that very deep neural networks require a lot of computation and lot of this computation can happen very quickly on gpus as opposed to cpus so people started using gpus for training and that drastically reduced the training and inference time so that was again something which sparked a lot of interest right because even though these were successful they were taking a lot of time to train but now the gpus could even take care of that and this success continued"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_14_0.wav", "duration": 13.0, "text": "so we move on to the next module and now we will write pseudo code to for back propagation"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_14_1.wav", "duration": 40.0, "text": "so we have all the pieces of the puzzle we have the gradients with respect to the output layer that was the special layer because the output activation function is different they are the gradients with respect to all the hidden layers that means i have the gradients with respect to the activations as well as the pre activations so in the h\u2019s as well as the a\u2019s and i also have the gradients with respect to the weights and the biases and this is all index agnostic right that means i am just using k as the index everywhere i have a generic formula which applies at any layer for the weights as well as the activations and the pre activations right ok now we can put all this together into a full learning algorithm so let us see what the pseudo code looks like"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_14_2.wav", "duration": 66.0, "text": "so we have this t equal to zero well run this for some max iterations we initialize all the parameters to some quantity will randomly initialize them ok now for these max iterations can you tell me what is the first thing that i will do so there will be two functions here ok tell me what those two functions would be student forward forward propagation and then backward propagation right so you do a forward propagation and you compute all these activations pre activations output layer loss everything and then you do this backward propagation where you feed all these things which you have computed these are the quantities which you have computed you will pass this to your backward propagation algorithm it would not look so nasty as this it will not take so many parameters you could write it smartly and then you will just do the parameter update so what will the back propagation give you actually all the gradients all the partial derivatives right and then once you have the partial derivatives you know how to compute the update law so now let us look at these two functions more carefully the forward propagation and the backward propagation"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_14_3.wav", "duration": 36.0, "text": "so forward propagation is simple for all the hidden layers that means from layer one to layer l minus one what will i do give me the code a k is equal to good then ok and what it what is h of zero you are starting the loop from one right so you will need h of zero that is x and then you will have a special treatment for the output layer and your final output will be whatever output function you use ok this makes sense you can write this in python you will have to write this in python"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_14_4.wav", "duration": 619.102, "text": "now we have computed all the h\u2019s and the a\u2019s what have we computed all the a\u2019s all the h\u2019s and all and the y right now you want to do back propagation so back propagation the loop will be from i equal to one to n minus one good so the first thing i will compute is the gradient with respect to the output layer see even here the output layer was outside the loop the same thing would happen here also in the back propagation also first you will compute the gradient with respect to the output layer and this is the formula if you remember from last class right that is the formula which i have substitute here and note that f of x is known to you because you computed that in the forward pass and e of y one hot vector which with a correct label said to one and you know what the correct label is because we have given you the refer time three hundred and fourteen data right ok then what would the loop be l to one or l minus one let us see first you compute the gradients with respect to parameters it is l so because we are using k minus one then you compute the gradients with respect to the layer below computes gradients with respect to the pre activation right this is exactly how you will proceed this is clear to everyone the same three components that we have used you might be a bit confused about the ordering in which we have put them because we computed the gradients with respect to pre activation first and then the weights but once you go back you will realize because it is the way we have indexed it because this is already outside so this has already been computed so you can already compute the gradients with respect to the weights of the outermost layer is that fine so this is straightforward you can go back and check this ok now anything remaining or you have everything can you just take a minute and see if you can visualize the python code and we will just assume that you are done the assignment you can read you will have multiple these vectors and matrices and so on and you are just doing a lot of matrix operations using refer time four hundred and six or refer time four hundred and eight or whatever you prefer right now what is missing here input is missing ok input we have given right the ominous data set has been given is there something that yours i have still not shown you how to compute oh i did not update the parameters here is it no the parameter update will happen in the outer loop right so those forward prop back prop and then update the parameters right so the main algorithm was forward prop back prop update the parameters when we saw forward prob an obvious seeing backward prop so what is missing one thousand iterations something in the last line before end of course do you know how to compute this"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_15_0.wav", "duration": 19.0, "text": "we have that activation function and we were taking the derivative of the activation with respect to pre activation and i just pushed it under the rug by saying we will write it as g dash so i need to show you what g dash is"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_15_1.wav", "duration": 877.623, "text": "what how to compute g dash so this is suppose g is the logistic function ok so that means what is z actually it is one of those a\u2019s right so this is the activation that you are going to feed it right and then you are taking the element wise sorry z is actually the pre activation that you feed it and then g is the activation function so i will do element wise activation function now what is the derivative of this so i will just i will not do this derivation it is there and you end up with a very neat formula which is g of z into one minus g of z so now that bit is also taken care of is there any more spoon feeding that i can do you are ready for the assignment now i will do one more bit you will also have used a tanh function so this is the derivative of the tanh function it again boils down to a very neat formula which is one minus g of zd whole square so we will end this lecture"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_16_0.wav", "duration": 41.0, "text": "so for the next module we need something known as cross entropy so we will just try to make some develop some intuitions for cross entropy and get to the formula for that and then i will tell you how it relates to the problems that we deal with ok so first let us start with something simple that what is it that we are trying to do ok so with that i will give you an example and i will ask you a few questions and then from there we will slightly try to go towards cross entropy so now suppose you have an urn which has thousands of balls and these balls are of three different colors which are red black and white"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_16_1.wav", "duration": 326.731, "text": "so you have an urn which has three different types of and there are many such balls which you have put in it and since you have put in it you know how many red balls are there how many blue balls are there and how many white balls are there so for you it is very easy to compute the probability of each of these things so that is say our probability is twenty-five thirty-five and four now talking more formally what is happening here is that you have a random variable x which can take on the values red blue or white right and this is the probability of each of those or the random variable x taking any of these values ok so this is the setup now i am your friend and you tell me that you can peep into the zone you cannot actually count take out all the balls and count them and estimate the probability we can just take a look into this and try to give me an estimate of what these actually what are these probability values that means what is the value so what is the probability that x is equal to red or x equal to white or x equal to blue so i just take a look at it turn it around a bit and try to get some feel ok i see a lot of red balls but a fewer blue balls or white balls and so on and based on that i make my best estimate right so i will just say that maybe these probabilities are thirty-five forty-five and two right so this is actually the true distribution i will call it as p right because this is the correct one and what i have estimated i will call it as q and remember now p has you can think of p as a vector which has these three values p one p two p three because there are three possible events here and similarly q has three values q one q two and q three so in this case i clearly know that i am wrong or when i give you these values you know that you are wrong so you tell me that whatever you have estimated is wrong then i obviously ask you tell me how wrong was i so how would you give me that number that is the thing that we are interested in so the general problem that we are interested in is that there is a true probability distribution and there is an estimated probability distribution and we want to find out how bad was the estimation now can you tell me a simple way of computing this it may not be correct but still it makes sense student squared error you can just take the squared error so what you are essentially telling me is that you could just treat these two as any other vector right and you could take the squared error difference between these quantities so what you are telling me is this where i goes from one to three ok so this is one valid way of doing this but then we are ignoring the fact that this is a distribution and hence it has certain properties that the sum of the elements is one and so on all of them are positive and things like that so we are ignoring those kind of things we are completely ignoring the fact that we are not dealing with a normal vector but a spatial vector which happens to be a distribution so now we want to find out a more principled way of computing the difference between two distributions and in practice why are we interested in this because we will always have a true distribution and a predicted distribution so that is what we want to do we have some way of computing it but you want a better way of computing it now let me make a case for why do we care about such differences right so let me take a simple case of a classification problem and to motivate that i will start from a different example and then i will come to the classification problem suppose there is a tournament going on and there were four teams which leads the semifinals let us call them a b c d ok now you were following the tournament up to the semifinals and after that you didn\u2019t watch the tournament and you do not know who eventually won well the tournament is over and someone has won it i actually watched the tournament and i know that b has won it now can i express this in terms of a probability distribution right so first let us look at what is the random variable here what is a random variable here the team which won right so that is my random variable and it can take one of these four values now i know that team b won because i saw the tournament and i have seen that they won so now how can i write this as a distribution what is the distribution comprised of it comprised of these probabilities assigned to each of these events and there are four such events here so how do i write this distribution so what you are telling me is i could write it as zero one zero zero so essentially they are telling me that all the probability mass is focused on one of these outcomes because that is the certain outcome that is already happened no one can change it so that is the outcome for this tournament so i know that the probability of that even is event is one and everything else is zero so in other words the probability that the random variable x takes on the value b is one and everything else is zero so what i am trying to tell you is that even for a certain event you could still write it in terms of a distribution where all the mass is focused on that event now again i will bring the same setup that i did not watch the tournament after the semifinals so now you ask me give me your prediction what which team would win or this is the prediction which i made before just after the semifinals or just before the semifinals that i think one of these teams is going to win the tournament and the chance of each of them winning is something like this so i know the teams i follow this sport and i probably know that ok b has a very strong team and they have a very good record in the past few months and so on so maybe they have a higher probability of winning so these are the numbers which i assign now again i have made an estimate was my estimate perfect when would it have been perfect if i had predicted with certainty won that b is going to win but i was not willing to bet everything on b so i said there is a very high chance it will win but there is still a chance that there could be some surprises now how wrong was i now again tell me can you tell me what is p and what is q here this is the true distribution and this is my predicted distribution and what am i interested in again the difference between them how wrong did i go and what again what is a simple way of doing this again square errors so again this is what my formula would look like so this is fine in this toy case but why do we care about in real life examples that we are going to deal with in machine learning so in watching learning will deal with a lot of problems which are classification problems and in classification problems you would again have this setup where you have a label the good thing of the label as a random variable and it could take off one of many values so i will again assume that it could take suppose you are trying to take a picture of fruits and you are trying to classify them and i could again think that i have four fruits say apple banana cherry and dragon fruit ok and this random variable can take one of these four values depending on the image that i am seeing ok now i have been given some training data so for every training data i have been given an image and i have been given the correct label so for that training data what is this distribution suppose i have been given the image of a banana what does this distribution look like zero one zero zero right again i have seen it so i know it is certainly a banana so i do not have any confusion all the probability mass is focused on that now the same image we are going to show to one of our models ok and it is going to make a prediction and will again ask it to give us a distribution the model will give us values perhaps like this ok so this is the models prediction again the model has given us a distribution and we have a true distribution and we are interested in knowing how wrong the model was so that student correct the refer time nine hundred and twenty-six we can correct the parameters of the model so this is our dash function loss function right so a loss function is some notion of difference between p and q right and so far we have been dealing with a very simplistic notion of this difference which is just the squared error loss ok and we want to do something better than this right so what i have told you is that you could always have a true distribution always have a predicted distribution and you would be interested in finding the difference between them that is the one first part the second part is that even when you are given something with certainty you could still write it as a distribution such that all the mass is focused on that event which was which has happened right which was the label was banana in this case and then you could still predict this from your model and now you are interested in knowing how wrong you are model wind because that is the loss function that you will use and then you will try to update your parameters with respect to this loss function means that is the setup that we are interested in so that is so i made a case for why we need to find differences between two distributions how to do it in a more principled manner we have not seen that yet we will get to that ok so before i get that i also need to tell you something about expectations so let us written to as sports example where there were four teams and say based on pundits and that sport they have said that these are the probabilities of winning and now you are into betting and you bet place your bets on these teams and you place our bets in a way that suppose team events then you end up winning ten k rupees if team b wins then probably will end up winning five k rupees and if team c wins probably ten k and if one of the other team wins maybe will end up losing money or something like that now you want to know what is your expected reward so now let us see what is happening here this was a random variable which could take on one of these four values these are the probabilities of the random variable taking that value taking on the value a or taking on the value b c and d ok this is your value or the gain or the profit associated with the random variable taking one of these values so you have a random variable you have a probability associated with every value of the random variable and you have some gain or value associated with every value of the random variable now how do you calculate the expected gain or expected profit which is this there is a thirty percent chance that you will earn ten k there is a forty percent chance that you will earn five k there is a twenty percent chance that you will earn ten k and ten percent chance that you lose thirty k so the way you will compute it is that and this is the simple expectation formula which is the probability of now the event here belongs to abcd right this is one of the four teams that will win probability of that event happening in to the value associated with that event happen this is a fair computation you get the intuition that this is how you will compute the net reward that you have so this is how you compute the expected value with respect to a particular distribution so this is the background that we need now i will just go on to the next slide and now we will talk about entropy first perhaps information content be first then entropy and then cross sector ok so now what is information content"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_17_0.wav", "duration": 68.0, "text": "welcome to lecture five of the course on deep learning and so today we look at some variants of gradient descent so we will just quickly do a recap of gradient descent and then look at some variants of it or some ways of improving it which is momentum based gradient descent nesterov of accelerated gradient descent stochastic gradient descent adagrad rmsprop and adam so just to set the context so we started with this gradient descent algorithm for a single sigmoid neuron and then we saw how to extend to network of neurons with back propagation so we realized that all we need is the gradients or the partial derivatives with respect to all the weights and biases once we compute that we can just use the gradient descent update rule now today what we are going to see is are there better update rules which lead to faster conversion or better performance in various ways so that is why we are going to look at all these different variants or methods of improving on gradient descent so that is the context"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_17_1.wav", "duration": 28.0, "text": "i will just quickly rush through so for most of the lecture i have borrowed ideas from the videos by ryan harris on visualize back propagation and some content is based on this course by andrej karpathy and others when i talk about some tips for learning rate and so on so you can just look at those also so we will just quickly rush through the first two modules which we have already done"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_17_2.wav", "duration": 6.0, "text": "which was we were interested in learning the weights and biases for this very toy network with just one input and one output and we started by doing something known as guesswork where we were just trying to adjust these weights and biases by hand"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_17_5.wav", "duration": 8.0, "text": "and we realized that its clearly not good and but we still try to do a very smart guess work where we were driven by this loss function which was telling us whether this guess the current guess is better than the previous guess or not and we just kept following our guess work and try to reach to some solution and for this toy network it was very easy to do that"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_17_7.wav", "duration": 21.0, "text": "and what we were actually doing is there is this error surface which exists which can be plotted for all possible values of w comma b and what we were trying to do with this guesswork is trying to find path over the error surface so that we enter into the better regions so red is bad blue is good the darker the shade of blue the better and this of course becomes intractable when you have many parameters and so on"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_17_8.wav", "duration": 10.0, "text": "so we wanted to have a better way of navigating the error surface so this is exactly what we were doing with the guesswork algorithm"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_17_9.wav", "duration": 7.0, "text": "so then this better way actually we realized that we could arrive at it from a very principled solution from starting from taylor series"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_17_10.wav", "duration": 3.0, "text": "and we went to this derivative where we finally came up with this rule that move in the direction opposite to the gradient"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_17_12.wav", "duration": 27.0, "text": "so that is the rule that we have been sticking to since then and we also along the way realize some of these things which we defined carefully which was what is what exactly this quantity means which is the partial derivative with respect to w evaluated at a particular weight comma bias configuration and because this is an iterative process you are at a certain value of weight and bias and you need to change it from there"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_17_13.wav", "duration": 242.0, "text": "and we then created an algorithm out of this and when we ran this we actually derived the full derivative and so on"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_17_14.wav", "duration": 8.0, "text": "now now you might say that this was only that special point again and i always get those questions so let us see what happens if you start from a different point"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_17_15.wav", "duration": 319.029, "text": "so now again the same gradient descent algorithm i am going to run but instead of starting at this point which was my random initialization i just happened to choose a very different random initialization which is here everyone sees that now let us see what happens what do you expect initially fast movement because the steep the slope is a bit steep now what would happen it will become slow because you have entered a gentle slope region and then again fast right so and then again it will become slow so see in this gentle region right the changes in w are so small that all your black points are actually indistinguishable from each other it is almost like a snakes body whereas in these steep slopes you can see a large change in the w you can see gaps between the values of w right so this is irrespective of where you start from gentle means slow movement steep means fast movement that is the basis"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_18_0.wav", "duration": 6.0, "text": "so we look at something known as contours"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_18_1.wav", "duration": 31.0, "text": "so now visualizing things in 3d can sometimes become a bit difficult especially for the person who is making the slides so we can can we do a 2d visualization of this traversal have i done this in the ml course no good can we do a 2d visualization of this traversal along the error surface so for that we need to understand something known as contours how many of you have looked at contour diagrams before how many of you know how to read them all of you know how to read them"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_18_2.wav", "duration": 173.0, "text": "so let us see now suppose this is what my error surface looks like and i have a single scalar variable so this is just a function of w for example and this is what my error surface looks like now what i am going to do is i am going to take horizontal slices on this error surface fine now can you tell me how this is going to look from the top sorry let me you should start answering before understand the question this is this error surface is actually so i was wrong in saying this is theta assume this is w comma b and you are just seeing the front view of the error surface what you are seeing here is just the front view this error surface is actually like a dementors hat so right so imagine that it is a hat place like this and you are just seeing the front view of this otherwise a top view does not make sense right so now i am going to slice this hat at two vertical positions and now you are looking at it from the top what are you going to see student ellipsis ellipsis everyone agrees with that"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_18_3.wav", "duration": 10.0, "text": "so i will just give you a couple of exercises and you have to tell me whether you understand this or not"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_18_4.wav", "duration": 260.0, "text": "so i have plotted a three d surface or two d i have what is this student refer time three hundred and fifty-four no student there is a contour there is a contour everything is not going to look like clean circles always right ok so this is a contour every line that you see here represents one cut along the vertical axis right that means the error is the same there now what you are seeing is a contour i want you to guess the three d surface from this you just guess it i mean just keep it to yourself fine the color is the same right blue is good red is bad so blue means the darker the shade of blue the lesser the value of the error the darker the shade of red the higher the value of the error ok i want you to imagine the three d surface if you can do that then i will be sure that you understand what how to read a contour how many if we can imagine this you can just say yes right i can never figure out whether you actually speak it so let me help you with the first one and then we will do a few more so let us start with the extremes right so let me see how to do this so this portion i also need to do it for the video ok so let me just do it here so this portion what do you think about the slope there very flattish why because this is the line that you see and the other line is not even in the figure right so it is basically very flat the slope is very gentle is it a low region or a high region high region fine ok now what is actually happening here what is the slope here student high very high that is why these two regions are very close to each other so from this high region what is happening suddenly there is a slope and you are going down and you know you are going down because you are reaching a blue region right ok now what is happening here student very flat very flat and this also flat but slightly upper than the lower guy is that fine now can you all imagine this ok and is this what you thought it is perfectly yes right is exactly what you thought ok just a minute so the orientation here has been changed a bit right so this portion actually corresponds to this portion are the two this is clear this portion corresponds to this portion right the just orientated fine so you start off this high plateau region which is here then you start going down go down and then you see a fold here right that is this fold so you went to a darker shade and then you came up to a slightly lighter shade the shades are ok guess the 3d surfaces how many if you want to play this forever now start with the extremes the bad guys the good guys the plateaus and the valleys and then see how do you go from the plateau to the valley ok tell me the corners first this plateau or valley student plateau plateau this plateau higher than this or lower than this student lower than this lower than this this student valley this towards the valley it is still between red and blue right it is not like right down there and what happens to all these guys all are very steep slows all converging down into the valley so can you perfectly imagine this and you will tell yes when i say when i show you the three d surface right again you need to reorient yourself so this corner here is this corner this corner here is this corner so we had these two plateaus at the top we had this slightly higher valley slightly lower valley and then all of them going into a very deep valley you see that everyone gets this how many if you have a problem with this if you have a problem with this you will just sleep off in the rest of the lecture so i want you all to understand this very carefully i do not mind repeating it how many of you understand this you understand the regions with gentle slope student yes the regions where you have a steep slope and you end up into that valley which is the valley here can you point it out fine ok so we will move ahead"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_18_5.wav", "duration": 13.0, "text": "so now we know what contour maps are and how to visualize them and so on right so now we will try to see the gradient a descent algorithm instead of running it on the 3d error surface we will try to run on this 2d contour map"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_18_6.wav", "duration": 215.587, "text": "so this is what i already showed you right i started from here and i showed you how it comes here or something like this right that was the gradient descent let me just erase this ok that is something like what the gradient descent algorithm now again you just need to reorient yourself so let us see this corner is this corner this corner is this corner and so on right so you get the reorientation right it just shifted now i am going to start my gradient descent algorithm from here from this point ok everyone see is that ok i am going to start from there and you have to help me and i am not going to just keep clicking you have to tell me what is going to happen so what will happen initially fast movement slow movement student slow movement slow movement right so i am running it one two three four five six seven eight it just keeps running very slowly now what will happen student fast fast ok now you see actually you can see the arrows these arrows are the quantity the magnitude of the movement right so earlier this movement was so small that you could not even see the arrows i have been drawing arrows right from the beginning but you could not see them at the beginning now you can see them right now what will happen student slow slow right so you see the exact same movement that i did on the three d surface now you can visualize it on the two d surface right and you can easily tell me where it will go fast where it will go slow right and where it will just keep moving very drag its feet and so on ok so this is where it starts dragging its feet and the same thing happened when we were in this region right so just you just make the connection that we are in the corresponding three d region there ok fine so we are moving very slow and it just keeps running so that is where we lend this module so we just revised gradient descent we saw that things are proportional to the gradient that is why gradient descent and the smaller the gradient the slower the movement the larger the gradient higher the movement gentle the slope student smaller smaller the gradient steeper the slope larger the gradient"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_19_0.wav", "duration": 9.0, "text": "in this module we will look at momentum based gradient descent"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_19_1.wav", "duration": 239.0, "text": "so what were the observations about gradient descent that it takes a lot of time to navigate regions having a gentle slope so what is the practical implication of this in practice why it what does this need to what does this mean right it takes more time so remember we had said this max iteration equal to one thousand now if you are initialization happens to be such that you are stuck in this large flat region then those one thousand iterations just keep moving around that flat region right you will not enter into one of the valleys and valleys is what you are interested in right because values is where you will have some minima for your function right so if you have a very gentle slope then for one thousand iterations you will keep moving around that gentle slope right that is why this has a practical implication now this was because the gradient in these regions were small can we do something better that is the question right so yes we can and we will take a look at momentum based gradient descent"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_19_2.wav", "duration": 159.0, "text": "so let us see what this means right so it basically means that in addition to the current step also look at the history there are three guys who earlier pointed you in the same direction so maybe this direction makes sense right so start accumulating that and move faster"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_19_3.wav", "duration": 125.0, "text": "so now this is the code for momentum based gradient descent i will just give you a minute to stare at the code and see if it makes sense so this much part is ok you are just computing the gradients with respect to all the points right and now we are keeping this running sum ok which is the previous gradients and the current gradient right and then you are just subtracting that running sum now this looking black curve that you see here that is gradient this this guy ok this black curve that you see here that is gradient descent when i have run it for around one hundred iterations now i am going to run momentum base gradient descent and each click is going to be one step ok and i want you to observe what happens ok so slowly a red curve will start appearing on the figure initially it will not be visible so do not worry there is nothing wrong with your eyesight one how many if you already see the red part i see it two three four five six no now you can see it as is nothing great about7 eight nine i want you to observe something here eleven twelve thirteen fourteen came back right so gradient descent i ran it four hundred iterations it was just stuck here right this was a point and i ran this for less than like around fifteen or twenty is what we counted right and so already entered into the valley so momentum base gradient descent is good you see that wicked smile on my face and you know it is a trick question so we are moving fast right"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_19_4.wav", "duration": 69.0, "text": "even in the regions where the slope was gentle right that is the beginning of the beginning of our trajectory right this was the gentle region even that i was very quickly able to navigate right within five to six steps i was away from that part right so even in the regions where the slope was gentle i was able to move fast but is moving fast always good so would there will be a situation where momentum would cause us to run fast ago same thing now instead of walking you are in a car you ask the person at the security whether i should go there he says yes go in the right direction you keep moving there someone else you keep accelerating what will happen eventually you will go fast phoenix market city then what will you do student take a take a u turn come back again while taking a u turn what will you do student refer time nine hundred and fifty-seven overshoot and come to the signal and then go back again right so you see this you will end up taking a lot of u turns so let us change the input data a bit and see what happens to momentum based gradient descent"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_19_5.wav", "duration": 213.0, "text": "so this is what my data looks like now so this is not what my data looks like this is what my error surface looks like so earlier we had this error surface something like a flying carpet now i have a very peculiar error surface this is again for the two parameter problem right w comma b that means i want to learn a sigmoid function where i have these two plateaus at the top the dark red regions that you see and then a very sharp valley can you tell me how i would have come up with this kind of an error surface what are the points that i would have chosen just hold on to that part so i have this kind of an error surface fine the error is high on either side of the valley now could momentum be detrimental in this case yes no maybe i do not care i do not care fine"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_19_6.wav", "duration": 106.98, "text": "so let us look at we will come back to three d now we look at a three d visualization and a very different interpretation of what is happening i really want you to understand what exactly is happening in this example which i had picked up right"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_2_0.wav", "duration": 6.0, "text": "let us look at nesterov accelerated gradient descent"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_2_1.wav", "duration": 25.0, "text": "so now we know that momentum based gradient descent is good at these gentle regions it moves really fast but we do not still do not like it because it has this problem of oscillations it has this problem that it overshoots its objective its goal and then it has to take a lot of u turns so can we do something about reducing this oscillation so the answer is always yes so let us look at nesterov accelerated gradient descent"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_2_2.wav", "duration": 53.0, "text": "so the idea here is very simple look before you leap ok now remember that this was the update rule for momentum based gradient descent ok and i will write it down again wt plus one is equal to wt minus gamma into update t minus one minus eta into the gradient at the current point so you see that actually i am taking two steps one is this step and then one more step and i could just this is one way of visualizing right that i move according to the history and then i move a bit more according to the current gradient so everyone sees that there is a two step movement happening here now can you think what could have been done look before you leap so we will see what we can do"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_2_3.wav", "duration": 78.0, "text": "so we know that we are going to move at least by this one and that is fixed we know that our history is telling us to move at least by this one and then we will move a bit more by the gradient so now can you think about it i am at least going to move this much what if i had some way of looking ahead and then do something at that point this is what you are saying of course i can verify it but i am sure it will become clear once i show the equations but i just want you to think about it a bit wait it is very simple it will become absolutely clear once i show you the answer but just think about it a bit so here is the answer it why not compute the gradients add this look ahead point right so you are again adding it in two steps minus the history and then minus the current gradient so take this value call it the look ahead point i know that i am going to move by this much so let me not compute the gradients at the current point let me move by this much then compute the gradients and see what happens at that point"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_2_4.wav", "duration": 103.0, "text": "so this is the equation right that first i move by that one step i had to make a two step movement so i will move by that one step right then i will compute the gradient at that position not at my current position right this was earlier gradient at point t now i have already moved a bit so i can compute the gradient there and then move in the direction of that gradient so you understood this that there is a two step movement right wt minus history minus the current gradient gradient computed at time step t ok now you know that you are already going to move by the history right so why not just move there and then compute a gradient at that point you are anyways made some movement you compute the gradient at that point and then decide which is the direction to move in right so that is what this look ahead value is i know it is still not clear to many of you and i am very confident it will become clear in the next five minutes we will show you one more visualization for this but this stay with stay with me for a while as long as you get the intuition i am fine i will move ahead and then i will explain it again in a different way this is fine ah that should become clear good that you asked that question ok so ask me again on the blank slide that i have and then i it should be complete so for right now let me just show you what will happen with the code and then i will again explain it with a different way"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_2_5.wav", "duration": 517.74, "text": "so this is what momentum based gradient descent it ok now let us see what nested or accelerated gradient descent will do again the code is simple you can just read it up and i have started executing you see this blue curve coming over there fine ok and now i keep running this now what will happen you see that all the u turns of the blue curve are inside the u turns of the red curve so the objective is being achieved at least empirically i have showed you that right its taking shorter u turns what is probably not clear to all of you is why is this happening is it clear to everyone why is this happening can everyone visualize that ok so let us see why this is happening i will give you an alternate explanation for this"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_20_0.wav", "duration": 10.0, "text": "now we look at stochastic and mini batch versions of these algorithms"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_20_1.wav", "duration": 5.0, "text": "so we will digress a bit actually we should have ended up somewhere else but i was just going to digress a bit"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_20_2.wav", "duration": 63.0, "text": "so this is the original gradient descent code that we had and i have highlighted something in this red box so notice that the algorithm actually goes over the entire data once before making an update it has going over this entire for loop which is over all the data points of course in this toy example i had only two data points but in i practice i will have many many data points i go over all the data points compute the derivatives and then make this one update student refer time fifty-seven because that is the right thing to do ok this was the exact formula that we painfully derived right that the gradient with respect to the loss function right which we had the summation i equal to one to n remember and the true derivative was a sum of the derivatives with respect to all the data points that is what we analytically derived and hence we are doing that it was that is the right thing to do not for any other purpose ok that is what it should always be right so that is the right thing to do because this is a true gradient and we actually derived it"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_20_3.wav", "duration": 68.0, "text": "and hence this was not an approximation so all the theoretical guarantees hold if i do this i know that now this is the true gradient or the true derivative and if i move in the direction opposite to the gradient everything falls in place because i proved it using taylor series but what is the flip side of this this is the right thing to do but what is the flip side if you have millions of point we will go over all these million points and make this one update now imagine the consequence when you are in a plateau region right even that momentum or whatever your movement in the plateau is going to be relatively smaller right you are going over these million points and making that tiny delta update right so imagine how much time it will take your algorithm to converge you get the problem so the algorithm will take a million calculations and then make one tiny update to your w ok this is going to be very slow can we do something better always right so let us take a look at stochastic gradient descent fine"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_20_4.wav", "duration": 43.0, "text": "so i have done a very subtle change to the code what is it do not tell me indentation but that is what i have done so you can tell me that so what is happening now for every data point i am making an update to my w values now the algorithm updates the parameters for every single data point if you have a million data points how many updates will be make in one pass over the data a million for every data point will make an update right so that slowness factor in what is known as batch gradient descent right batch gradient descent is when you look at the entire data and then make one update"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_20_5.wav", "duration": 218.0, "text": "what is the flip side what does this module titled stochastic gradient descent so what is the flip side these are not the true gradients the true gradient is summation over all the points now this is no longer the true grading this is just a point estimator this is just a approximation of the gradient right and stochastic because we are calculating the gradient based on a single data point right it is a sampling one data point and computing the gradient that this is what the entire population looks like right this is almost similar to tossing the coin once and saying that this is what the probability of heads is if it lands at heads then the probability is one otherwise its zero right you see the error you see the problem with that right as opposed to tossing the coin a thousand times and then deciding the probability is just tossing it once so this is always going to be a erroneous right this this is going to be bad so now there is no guarantee that each step will decrease the loss why because the guarantees were only when you are doing the right thing which was to compute the gradients over all the data points now there is no theoretical guarantees right because it is all stochastic now so it is possible that in a particular data point your loss might increase also the overall loss on the data with respect to that point it might decrease but the overall loss right so now let us see this algorithm in action and i want you to make certain observations about this so this is the code that i am going to run now so let us see"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_20_6.wav", "duration": 236.0, "text": "so we look at a mini batch version of this so what i am going to do is instead of so this code is actually for mini batch stochastic gradient descent it is a very minor alteration on the stochastic gradient descent i will just let you stare at it for a minute or so what i am doing here is i am instead of doing it for every point i am waiting for a certain number of points and then making the update right that is what i am doing here now for this i have kept k equal to two what does that mean i look at two points compute the derivatives with respect to them and then make an update for two points at a time what do you expect no what do you expect with respect to this code"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_20_7.wav", "duration": 9.0, "text": "so similarly we can have the stochastic versions of momentum based gradient descent and nesterov accelerated gradient descent"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_20_8.wav", "duration": 51.004, "text": "so these are just the codes it is very easy to see what is happening here again basically this is just an indentation right so if you look at the difference between the two codes i have just indented it inside that means i am making these updates for every data point right and same thing you could do for nesterov also"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_21_0.wav", "duration": 7.0, "text": "tips for adjusting the learning rate and the momentum"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_21_1.wav", "duration": 7.0, "text": "so before moving on to these slightly advanced optimization algorithms we will revisit the problem of learning rate in gradient descent"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_21_2.wav", "duration": 33.0, "text": "so one could have argued that we could have solved this problem of this slow movement on the gentle slope by increasing the learning rate remember that we have this eta and we deliberately chose to be conservative that we will take a small value for the eta but what if i just blow up the eta i could just take a very large eta what would happen it will overshoot right so what will happen is i will see what happens when i take eta equal to ten ok so so i will see what happens when i take eta equal to ten"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_21_3.wav", "duration": 494.0, "text": "so this is step1 step two step three its moving very fast on the regions where the slope is gentle but it also moves very fast much faster on the regions where the slope was already steep so when the gradient was actually high you ended up blowing it further by multiplying it with the eta which is ten so it is again going to have this effect that you will move much faster in the steeper regions and again you will see these oscillations because you will overshoot your objective does that make sense right so it is not that you can always choose a high eta and get away with it so what do you actually want what is your wish list regulate theta you want a adaptive eta right that it somehow figures out that i am on a gentle slope so i should move slowly i should move fast and i am now on a very fast loop so i should move slow so this having this one eta is not working for every point on the error surface right for everywhere on the error surface is that clear ok so ok so we will see such algorithms soon where we try to adjust this learning rate"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_21_4.wav", "duration": 1298.91, "text": "now tips for the momentum can you make sense of this you just stare at it it looking just come back ok let us see what happens at t equal to zero this becomes zero student log one log one is zero this is two raise to minus one minus zero which is just two raise to minus one which is five so what is your mu t at t equal to five does that make sense is it fine with everyone or is it confusing no ok mu max is typically this let us assume mu max now what happens at time step two hundred and fifty this is two hundred and fifty by two hundred and fifty so this becomes one one plus one is two the best thing that you learn in this course log of two is one so this become two raise to student two raise to minus two minus two which is twenty-five so what is this student seventy-five seventy-five let us do one more i had t equal to seven hundred and fifty one minus one by eight so that is what is going to be right ok so then what is happening as my time steps are increasing what is happening to what is happening i am having more and more faith in the history or the current gradient what am i increasing actually i have made a mistake actually this is mu is gamma there is not we did not use mu anyway what you guys just went along so this is gamma actually right that was a momentum term that we had so as a number of time steps is increasing my gamma is increasing that means i am having more and more faith in my student refer time one thousand, one hundred and forty-nine no history learning rate is eta momentum is gamma so its gamma into update t minus one and eta into gradient at the current time step right and here gamma is actually equal to mu is there any more confusion that i can add so when i say gamma i mean mu and so that is how it is so as i am increasing the number of time steps i have more and more faith in the history that means i do not want to now get distracted by this one update which i am making right i want to go by the history and i am not increasing this gamma or mu indefinitely i am capping it by a max right max i will have this much faith which is nine hundred and ninety-nine in the history does that make sense this is again just a heuristic do not worry too much about it so that is how it is"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_22_0.wav", "duration": 154.0, "text": "so we were looking at these different variants of gradient descent we saw that gradient descent has this problem that it finds it difficult to navigate the gentle slopes so we came up with tricks on momentum based gradient descent and also nesterov accelerated gradient descent the trick in momentum was that if lot of your history is telling you to move in a direction then just continue to gain momentum in that direction so instead of just updating based on the current gradient you also update based on the history right and there we saw that this is always going to be a problem that you will end up taking uturns and we had this analogy of how you look for directions and you just overshoot your destination and have to come back and take a uturn and come back and so on so to prevent that we realize that the update done by momentum base gradient descent is two step update you actually the first step is based on the history and then another step based on the gradient at the current time step right so then instead of doing these two steps at one go why not just update based on the history see what the gradient that tells you and then we saw this nice figure i hope it was nice and where you saw that if you look ahead point then you will be immediately corrected with respect to your errors so that was about nag and momentum then we saw the stochastic versions of these algorithms where we realize that if we do the batch version then you go over a million points and then make only one update which could be very slow in cases where you have large data so we then decided to the stochastic version where we just update for every point that again had these oscillations because we were taking greedy decisions we were just relying on one point to tell us which was the right direction to go on and you saw that these esteem has become better as you increase the value of this k so k equal to one is the most stochastic version and then k equal to two you get the mini batch version and then you could just have different values of k so that you have more reliable estimates of the gradients and in the limit if you have the entire data then you are just doing the full batch gradient descent right this is the vanilla gradient descent anything else did we cover then we had some tips on the learning rate and the momentum these are again heuristic i gave you some ideas and you could try these in your back propagation assignment and see which one works better for you you could see you have any peculiar observations while implement the back propagation assignment so now there are a few more things left in this lecture so i will start with the line search first so this is one more thing before you move on to some more interesting algorithms which are the current state of the art and lot of deep learning solutions"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_22_1.wav", "duration": 1939.669, "text": "so most people that you read would look at would have algorithms that we will see after ten minutes"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_23_0.wav", "duration": 47.0, "text": "so around one thousand, nine hundred and fifty-nine hubel and wiesel did this famous experiment they are still i think you could see some videos of it on youtube where there is this cat and there was a screen in front of it and on the screen there were these lines being displayed at different locations and in different orientations so slanted horizontal vertical and so on and there are some electrodes fitted to the cat and they were measuring trying to measure that which parts of brain actually respond to different visual stimuli let us say if you show it stimulus at a certain location does the different part of the brain fire and so on so and one of the things of outcomes of the study was that that different neurons in brain fire to only different types of stimuli it is not that all neurons in brain always fire to any kind of visual stimuli that you give to them"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_23_1.wav", "duration": 18.0, "text": "so this is essentially roughly the idea behind convolutional neural networks starting from something known as neocognitron which was proposed way back in one thousand, nine hundred and eighty you could think of it as a very primitive convolutional neural network i am sure that most of you have now read about or heard about convolutional neural networks but something very similar to it was proposed way back in one thousand, nine hundred and eighty"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_23_2.wav", "duration": 43.0, "text": "and what we know as the modern convolutional neural networks maybe i think yan li kun is someone who proposed them way back in one thousand, nine hundred and eighty-nine and he was interested in using them for the task of handwritten digit recognition and this was again in the context of postal delivery services so lot of pin codes get written or phone numbers get written on the postcards and there was a requirement to read them automatically so that they can be the letters or postcards can be separated into different categories according to the postcard according to the postal code and so on right so or the pin code so that is where this interest was there and one thousand, nine hundred and eighty-nine was when this convolutional neural networks were first proposed or used for this task"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_23_3.wav", "duration": 30.0, "text": "and then over the years several improvements were done to that and in one thousand, nine hundred and ninety-eight this now how famous data set the mnist data set which is used for teaching deep neural networks courses or even for initial experiments with various neural network based networks this is one of the popular data sets which is used in this field and this was again released way back in one thousand, nine hundred and ninety-eight and even today even for my course i use it for various assignments and so on"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_23_4.wav", "duration": 925.669, "text": "so it is interesting that an algorithm which was inspired by an experiment on cats is today used to detect cats in videos of course among other various other things is just i am just jokingly saying this"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_24_0.wav", "duration": 21.0, "text": "in this module we look at gradient descent with adaptive learning rate so first we will see motivation or intuition for why we need this and once you get the motivation i believe the rest should be straightforward"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_24_1.wav", "duration": 385.763, "text": "so far what we have been doing is please pay attention on this slide i need to define some notations and you should not get confused with that so far we have been dealing with the situation where we had just one feature which was x and one weight corresponding to it which was w and one bias which corresponded always on input right now we are going to look at the situation where we have more than one inputs that means earlier we were basing our predictions only based on the director and now we are the director actor genre imdb ratings and so on so here x one x two x three x four these are four different features or four different inputs that i have and this is not x square just i know it is obvious but i am just making it clear right so this is x one x two x three x four ok it is not probably the best choice of notation but i will just stick to that so now each of these has a corresponding w one w two w three w four ok and this is how your decision looks like it is the dot product between the weight vector and the input vector ok this is how i am going to decide and that is a single sigmoid neuron again now given a single point xy do i need to again go through this computation sorry w p oh sorry ok i will just erase this so this w is actually the vector w so it includes w one w two w three w four and i am trying to take the derivative with one element of that vector do i need to show you how to compute this have you seen this before can you tell me i will show you the derivative with respect to w one can you tell me it will be a product of some terms can you tell me what is the last term going to be"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_25_1.wav", "duration": 293.0, "text": "so in this video we will try to look at an explanation for why we need bias correction in adam or in other words i want to explain why do i do this particular step why did i take m t and v t as it is but why did i do this particular step which i called as the bias correction step"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_25_2.wav", "duration": 22.0, "text": "so in general m t we can write it as one minus beta as i equal to one to t b beta t beta raised to t minus i into g i right so this three is here i have just replaced them by t s right you can just verify that this is from you can just generalize from the third entry to the t\u2019th entry"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_25_3.wav", "duration": 13.0, "text": "so now let us see we have the following expression we have simplified the expression for m t and written it more compactly but what we were eventually interested in the expected value of m t right we wanted to show that certain things holds for the expected value of m t"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_25_4.wav", "duration": 1239.467, "text": "so you just take expectation on both sides so this is what we will get ok now one minus beta is of course a constant so i can move it outside the expectation so then i get an expectation of a sum now the expectation of a sum is the same as the sum of expectations so i can write it as a sum of expectations ok now again beta is a constant so i can take it outside the expect expectation so what i will be left with is beta raise to t minus i outside and expectation of g i right so this is actually expectation of g one when i equal to one then expectation of g two expectation of g three and so on now we will make an assumption that all these gi\u2019s that means the gradient at time step one the gradient at time step two the gradient as time step three and so on they all come from the same distribution ok we are going to make that assumption so let us try to understand the implication of that right so let us say this was a distribution from which g one came right suppose i am dealing with a scalar quantity and maybe this was the distribution from which g one came now g two could have come from a different distribution g three could have come from a different distribution and if that was the case then expectation of g one would be different from the expectation of g two and so on so what we have assumed to it will make things simple for us is that g one g two g three any g i comes from the same distribution and hence you can say that the expectation of all these gi\u2019s is going to be just the expectation of g that is this one single distribution from these which these entries come this of course a very strong assumption but we are going to live with this assumption"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_26_0.wav", "duration": 164.0, "text": "so this lecture actually is a bit of a digression and it is supposed to cover some of the basics that we need for various sections of the course so it is very important that you understand some concepts for linear algebra specifically eigenvalues eigenvectors and in particular today we will do principal component analysis and the reason that i do it is there is an very neat relation of pca and to autoencoders an autoencoder is something that well cover in the course it is a part of any deep neural network course and singular value decomposition is something that we using when we learn word vectors the word vector is again something very important i can just i can do the non svd version of it where i just talk about what word to wick is but that will not give you the same probably not the same interpretation as if you start from svd and then reach word vectors right so that is why i am covering these basics so how many of you know eigenvalues and eigenvectors very embarrassing question how many of you absolutely hate eigenvalues and eigenvectors so let us see if we can change that today i mean on the positive side"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_26_1.wav", "duration": 56.0, "text": "and that is exactly what eigen vectors do it right they refused to change their part they tell the matrix you can hit me as many times as you want probably you can increase my you could probably slow me down a bit or push me ahead or something but i am not going to stray off from your path right so that is what eigenvalue eigenvectors do so here is a matrix which is a villain and here is an eigenvector which is our hero and now when this matrix hits this eigenvector it refuses to stray from it is part right it says i will move forward i will move back whatever but i will not change my direction ok i will just stay honest to what i am and these vectors are called the eigenvectors i am more formally you can write it as ax is equal to lambda x right so that means the direction remains the same only the scale changes it will either get slowed down or it will get boosted up right so the magnitude would change but the direction remains the same"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_26_2.wav", "duration": 222.0, "text": "now what is so special about eigenvectors like why are why is it that they are always in the lime light i know the any course that you do invariably touch eigenvectors or eigenvalues at some point in that course right where be it machine learning image processing whatever you do you always speech everything that you do you will always have eigenvectors and eigenvalues why is it so well it is turns out that several properties of matrices can actually be explained away by looking at their eigenvalues so if i look at a matrix i would probably not be able to comment much on it but if you tell me something about the eigenvalues i can see a lot of things about of it and there is an entire field on this way this entire spectral graph theory which looks at properties of laplacian matrices and come in something on the properties of the graph and so on right and that is just an example which we do not care about but what we care about in this course there are a few things that we care about with respect to eigenvalues and eigenvector and that is what i am going to focus on right so that is what this lecture is going to be out and i will take two specific cases which are very important for us to understand certain concepts later on so i will start with the first one"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_26_3.wav", "duration": 349.471, "text": "and now this though a very toyish example can you relate it to many things in real life or many things that you will take in decision making right that you are so even if you are playing a game for example and even if you are playing atari games or something you are in a certain state based on some action that will take will move to a different state and so on right so these things happen in various real world applications right there is a certain state for example even in stock market prediction you are at a certain value of fish stock it might change to a different value right and these values you could just say them as high low or neutral that i am not going into the actual numbers today the stock value is high it does it possibility that it will transition to something low and so on right so these kind of state transition diagrams occur in various real world examples now this is a problem for the two restaurant owners right why is this a problem for the two restaurant owners they do not know how much food to make but every day the number of customers is changing right but is the number of customers actually changing will the system eventually reach a steady state will it is it obvious that it will reach a steady state or maybe it will not even reaches steady but the way i describe it i do not see why it should reach a steady state right you have some people here they go there come back go there and so on the only thing which i have assumed is that the transition matrix which was the matrix m is constant across all the time steps right so every day it is at the same priorities by which things are changed right so what is your guess if i were to ask you to take a guess ok let us see how many of you think and it is there is no correct answer here at this point so just tell me how many of you think it will reach a steady state how many of you think it will keep changing and why is the sum never equal to one ok so fine so it turns out that they will right and let us see how"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_27_0.wav", "duration": 956.308, "text": "so in parallelly while there was lot of success happening from two thousand and twelve to two thousand and sixteen or even two thousand and ten to two thousand and sixteen in parallel there will also a lot of research to find better optimization algorithms which could lead to better convergence better accuracies and again some of the older ideas which were proposed way back in one thousand, nine hundred and eighty-three now this is again something that we will do in the course so most of the things that i am talking about we are going to cover in the course so we are going to talk about the imagenet challenge we are going to talk about all those networks the winning networks that i had listed there alex net zf net google net and so on we are going to talk about nesterov gradient descent which is listed on the slide and many other better optimization methods which were proposed starting from two thousand and eleven so there was this parallel resource happening while people were getting a lot of success using traditional neural networks they are also interested in making them better and robust and lead for lead to faster convergence and better accuracies and so on so this led to a lot of interest in coming up with better optimization algorithms and there was a series of these proposed starting from two thousand and eleven so adagrad is again something that we will do in the course rms prop adam eve and many more so many new algorithms i have been proposed and in parallel a lot of other regularization techniques or weight initialization strategies have also been proposed for example batch normalization or xavier initialization and so on so these are all things which were aimed at making neural networks perform even better or faster and even reach better solutions or better accuracies and so on this all that we are going to see in the course at some point or the other"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_28_0.wav", "duration": 17.0, "text": "so i was talking about successes in image speech pattern recognition even natural language processing and so on so one interesting thing here is about sequences so i will talk about sequences now"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_28_1.wav", "duration": 80.0, "text": "sequences are everywhere when you are dealing with data so you have time series which is like say the stock market trends or any other kind of a series time series then you have speech which is again a series of phonemes or you have music you have text which is a series of words you could even have videos which are the series of images right one frame each image each frame can be considered to be an image and so on so in speech data one peculiar characteristic of speech data is that every unit in the sequence interacts with other units so words on their own may not mean much but when you put them together into a sentence they all interact with each other and give meaning to the sentence right and the same can be said about music or speech or any kind of sequence data so all these elements of the sequence actually interact with each other so there was a need for models to capture this interaction and this is very important for natural language processing because in natural language processing you deal with sequence of words or all your texts or sentences or documents or all sequences of words so that is very important and the same in the case of speech also so if you take up any deep learning paper nowadays it is very likely that you will come across the term recurrent neural network or lstms which are long short term memory cells and so on"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_28_2.wav", "duration": 2.0, "text": "so this is also something which was proposed way back in one thousand, nine hundred and eighty-six"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_28_3.wav", "duration": 34.0, "text": "so a recurrent neural network is something which allows you to capture the interactions between the elements of your sequence i had said at a very layman level but of course you are going to see this in much more detail in the course and this was also not something new even though you hear about it a lot in the past three to four years the first recurrent neural network and what you see here is exactly a very similar to what we are going to cover in the course was proposed way back in jordan by jordan in one thousand, nine hundred and eighty-six"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_28_4.wav", "duration": 41.0, "text": "its variant was proposed by elmen in 1990so this is again not a very new idea this has existed for some time but now there are various factors because of which it has been possible to now start using them for a lot of practical applications as i said one you have a lot of compute time and the other you have a lot of data and the third is now the training has stabilized a lot because of these advances which i was talking about in terms of better optimization algorithms better regularization better weight initialization and so on so it has become very easy to train these networks for real world problems at a large scale so that is why they have become very popular and hear about them on a regular basis but it is again something which was done way back"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_28_5.wav", "duration": 30.0, "text": "so from one thousand, nine hundred and ninety-nine to one thousand, nine hundred and ninety-four actually people also looking at various problems will be training neural networks and recurrent neural networks and so that this problem which is known as exploding and the vanishing gradient problem which is again something that we will see in the course in reasonable detail we have this problem and it is very difficult to train recurrent neural networks for longer sequences so if you have a very long sequence or a time series you cannot really train a recurrent neural network to learn something from that"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_28_6.wav", "duration": 49.0, "text": "and to overcome these problems around one thousand, nine hundred and ninety-seven long short term memory cells were proposed and this is again something that we will cover in the course and this is now almost de facto standard used for training for a lot of nlp work lstm are used as one of the building blocks and another variants of lstms which are known as gated recurrent units and some other variants so this is also not something new even though they have become very popular nowadays like almost any article that you pick about to talk about any article on deep learning that pick about to talk about recurrent neural networks or lstms or gated recurrent units this is not something which is new"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_28_7.wav", "duration": 70.0, "text": "lstms had come way back in one thousand, nine hundred and ninety-seven but again due to various compute and other issues which i said at that time it is not so easy to use them but by two thousand and fourteen because of these parallel progresses which i mentioned in terms of optimization regularization and so on people are now able to use rnns lstms for large scale sequence to sequence problems and in particular a very important discovery at this time are very important model which was proposed at this time which is attention mechanism which is used in a lot of deep neural networks nowadays which enabled to deal with a lot of sequence prediction problems for example translation where you have given one sequence in one language and you want to generate the equivalent sequence in another language so this is known as a sequence to sequence translation problem so for that people proposed a sequence to sequence attention network and this was one of the key discoveries which then led to a lot of adaptation of or adoption of deep neural networks for nlp a lot of research in nlp happened which was then driven by deep neutral networks so a lot of existing algorithms which are non neural network based algorithms which are traditionally used for nlp was slowly replaced by these deep neural network based algorithms ok"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_28_8.wav", "duration": 897.75, "text": "and again this idea of attention itself is something that was explored earlier also somewhere around one thousand, nine hundred and ninety-one or so and it was something known as reinforcement learning which was used for learning this attention mechanism what attention basically tells you is that if you have a large sequence and if you want to do something with this sequence what are the important entities of this sequence or elements of this sequence that you need to focus on so this is again something that we will look at in detail in the course"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_29_0.wav", "duration": 16.0, "text": "now since i mentioned rl so we will go on to the next chapter which was now becoming much more ambitious with what you can do with deep learning and people started beating humans at their own game quite literally"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_29_1.wav", "duration": 20.0, "text": "so there was this starting with atari games in two thousand and fifteen where resources from deep mind show that you could train a deep neural network to play atari games and do much better than what humans do so that is something that they were able to show on atari games and then people started looking at other game"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_29_2.wav", "duration": 20.0, "text": "so then there was this go and this popular tournament and which alphago which is deep reinforcement learning based agent was actually able to beat the reigning champion at that time one of the best players of go at that time"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_29_3.wav", "duration": 11.0, "text": "then even at poker were something known as deepstack which is again a deep reinforcement learning based agent which is able to beat eleven professional poker players at this game"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_29_4.wav", "duration": 657.191, "text": "then other games like defense of the ancients since on which is a much more complex strategy based game where again deep reinforcement learning based agents have shown a lot of success in beating top professional players on this game"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_3_0.wav", "duration": 18.0, "text": "so this was all happening where deep learning now started showing a lot of promise in a lot of fields nlp vision speech and again this deep reinforcement learning and so on which led to this complete madness starting from two thousand and thirteen"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_3_1.wav", "duration": 22.0, "text": "well almost for every application the traditional methods were then overwritten or kind of beaten by deep neural network based system so something like language modelling which has been around since probably 1950s or so now the reining algorithm or the better algorithm for language modelling is now something which is based on deep neural networks"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_3_2.wav", "duration": 18.0, "text": "then similarly for speech recognition lot of work a lot of probabilistic lot of work based on probabilistic models was done in this or in the speech area or the speech literature for the past thirty forty years and now all of that has been overcome by deep neural network based solutions"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_3_3.wav", "duration": 15.0, "text": "same for machine translation a lot of interest in this field a lot of companies now have their machine translation systems based on deep neural networks as opposed to the earlier phrase based statistical machine translations or the probabilistic models which were used earlier"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_3_4.wav", "duration": 27.0, "text": "similarly for conversation modelling dialogue a lot of new work started in dialogue post a deep learning era where people now realize that if you have a lot of sequences of conversations you could actually try to train a deep neural network to learn from this sequence and have conversations with humans of course you are nowhere close to human level conversations we are very very far off from them but in limited domains these bots are showing some success now"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_3_5.wav", "duration": 7.0, "text": "same for question answering where you are given a question and you want to answer it either from a knowledge graph or from a document or from a image and so on"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_3_6.wav", "duration": 20.0, "text": "and in the field of computer vision things like object detection most of the reigning systems or the best performing systems nowadays are deep neural network based systems a lot of advances are being made on these systems over in the last few years"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_3_7.wav", "duration": 4.0, "text": "same for visual tracking where you want to track the same person in a video or image captioning where you want to generate captions for images for example people upload a lot of images on facebook"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_3_8.wav", "duration": 24.0, "text": "and if you want to automatically caption them or imagine you are on a reselling site right something like olx where you upload your furniture and you do not provide a description from that but can the machine already automatically generate a description for it so it is easier for the human to read what that product is and so on"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_3_9.wav", "duration": 18.0, "text": "so similarly video captioning i given a video anyone to caption the main activity which is happening in that video all of these problems are being solved using deep learning based solutions using a combination of something known as feed forward neural networks or convolutional neural networks or recurrent neural networks and so on"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_3_10.wav", "duration": 5.0, "text": "visual question answering you are given an image and a question and you want to answer that question"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_3_11.wav", "duration": 3.0, "text": "video question answering answering questions from videos"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_3_12.wav", "duration": 11.0, "text": "video summarizations if you are given a large video and you want to generate a trailer a sort of a trailer for that video contains which kind is the most important frame for that video even these systems are based on deep learning"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_3_13.wav", "duration": 53.0, "text": "then this was all about classification recognition and so on but now people started getting more ambitious that can we humans are very good at creativity so can we use machines to be creative right to generate images so now if i have seen a lot of celebrity faces can i generate new celebrity faces or if i have seen a lot of bedroom images and i am if a fireman architect now can i generate new bedroom images can i can we train a machine to generate new bed bedroom images so a lot of phenomenal progress or work has happened in this field in the last four five years starting with things like generative adversarial networks variational autoencoders and so on and people are now starting to seriously invest into creativity that how to make machines creative again we are far off from where the desired output but there is still significant progress happening in this field generating audio"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_3_14.wav", "duration": 6.0, "text": "so that was about generating images you can generate music also"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_3_15.wav", "duration": 185.508, "text": "and this is again about generating images and so on"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_30_0.wav", "duration": 22.0, "text": "so lot of fields have adopted deep learning now and lot of state of the art ai systems are based on deep neural networks but now what is needed is after all thi s madness were deep learning has taken over a lot of research areas can we now bring in some sanity to the proceeding so this is really a need for sanity"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_30_1.wav", "duration": 203.0, "text": "and why i say that is that because there is this paradox of deep learning so there is this interesting question that why does deep learning works so well despite having a high capacity so the deep neural networks have a very high capacity which means that susceptible to over fitting so most of you would have done some course on machine learning so there you know that over fitting is bad because you are just memorizing the training data and then you might not be able to do so well and at tested and over fitting happens when your model has a high capacity so even though deep neural networks have high capacity why are they doing so well we will focus on this high capacity but when we talk about the universal approximation theorem and give some arguments for why deep neural networks have such a high capacity the other thing is they have this numerical instability right so we spoke about these vanishing and exploding gradients and again we will talk about this later on in the course so despite this training difficulties why is it that deep neural networks performs so well and of course they have this sharp minima which is again it could lead to over fitting so if you look at there is an optimization problem it is not a neat convex optimization problem so it is a non convex optimization problem so why does it still do so well so it is also not very robust so here is an example on the right hand side the figure that you show so the first figure is actually of a panda and the machine is able to detect this panda with some fifty-seven percent confidence right we have trained a machine for a lot of animal images we have shown it a lot of animal images at test time we show at this image the first image that you see on the right hand side and is able to classify this is a panda with fifty-seven percent confidence but now what i do is i add some very random noise so that second image that you see with some very random pixels if i add it to this image i will get a new image so every pixel in this image is added to this new noise image and i get the image which is see on the third the third image that you see right to you and me or to any average human this still looks like a panda there is hardly any difference between this image and the original image but now if you pass this to the machine all of a sudden instead of recognizing this is a panda it starts to recognize it as a gibbon and that too with ninety-nine percent confidence so why is it that they are not very robust and despite this not being very robust why are deep neural networks so successful so people are interested in these questions and people have started asking these questions there are no clear answers yet but slowly and steadily there is an increasing emphasis on explainability and theoretical justifications so it is not enough to say that your deep neural network works and gives you ninety-nine percent accuracy it is also good to have an explanation for why that happens is it that some components of the networks are really able to discriminate between certain patterns and so on so what is going on inside the network which is actually making it work so well right and hopefully this will bring in some sanity to the proceedings so instead of just saying that i apply deep learning to problem x and got ninety percent success we will also make some kind of more sane arguments just to why this works and what is the further promise of this and thinks like that so that is roughly a quick historical recap of where deep learning started and where it is today starting all the way back from advances in biology in one thousand, eight hundred and seventy-one to recent advances till two thousand and seventeen and so on deep learning right and here are few url"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_30_2.wav", "duration": 5.0, "text": "so you could take a look at this for a lot of interesting applications of recurrent neural networks"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_30_3.wav", "duration": 6.0, "text": "bunch of startups which have come up in this space is working on very varied and interesting problems and here are all the references that i have used for this particular presentation"}
{"audio_filepath": "/mnt/d/AI4Bharat12/Speech_to_text_WebScraping-main/output12/lecture_30_4.wav", "duration": 82.328, "text": "so that is where we end lecture one and i will see you again soon for lecture two"}
